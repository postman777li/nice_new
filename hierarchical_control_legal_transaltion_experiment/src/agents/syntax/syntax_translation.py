"""
å¥æ³•ç¿»è¯‘Agent - æ•´åˆå¥æ³•å»ºè®®å’Œç¿»è¯‘è¾“å‡º
æ”¯æŒå¤šå€™é€‰ç”Ÿæˆå’ŒCOMET-Kiwiè´¨é‡è¯„ä¼°é€‰æ‹©
"""
from typing import List, Dict, Any, Optional
from dataclasses import dataclass
import logging

from ..base import BaseAgent, AgentConfig, AgentRunContext

logger = logging.getLogger(__name__)


@dataclass
class SyntaxTranslationResult:
    source_text: str
    refined_text: str
    applied_corrections: List[Dict[str, Any]]
    confidence: float
    rule_updates: List[Dict[str, Any]]
    candidates: Optional[List[str]] = None  # å¤šä¸ªå€™é€‰ç¿»è¯‘ï¼ˆå¦‚æœç”Ÿæˆäº†ï¼‰


class SyntaxTranslationAgent(BaseAgent):
    def __init__(self, locale: str = 'zh', generate_candidates: bool = False, num_candidates: int = 3):
        """
        åˆå§‹åŒ–å¥æ³•ç¿»è¯‘Agent
        
        Args:
            locale: è¯­è¨€åœ°åŒº
            generate_candidates: æ˜¯å¦ç”Ÿæˆå¤šä¸ªå€™é€‰ç¿»è¯‘ï¼ˆé»˜è®¤Falseï¼Œåªç”Ÿæˆä¸€ä¸ªï¼‰
            num_candidates: ç”Ÿæˆçš„å€™é€‰æ•°é‡ï¼ˆä»…å½“generate_candidates=Trueæ—¶æœ‰æ•ˆï¼‰
        """
        super().__init__(AgentConfig(
            name='syntax:syntax-translation',
            role='syntax_translator',
            domain='syntax',
            specialty='å¥æ³•ä¿®æ­£ç¿»è¯‘',
            quality='review',
            locale=locale
        ))
        
        
        self.generate_candidates = generate_candidates
        self.num_candidates = num_candidates
        
        if self.generate_candidates:
            logger.info(f"âœ“ å¥æ³•ç¿»è¯‘Agenté…ç½®ä¸ºç”Ÿæˆ{num_candidates}ä¸ªå€™é€‰ç¿»è¯‘")

    async def execute(self, input_data: Dict[str, Any], ctx: Optional[AgentRunContext] = None) -> SyntaxTranslationResult:
        """æ•´åˆå¥æ³•å»ºè®®å’Œç¿»è¯‘è¾“å‡ºï¼ˆæ”¯æŒå¤šå€™é€‰é€‰æ‹©ï¼‰"""
        source_text = input_data.get('source_text', '')
        target_text = input_data.get('target_text', '')
        patterns = input_data.get('patterns', [])
        evaluation = input_data.get('evaluation', None)
        source_lang = input_data.get('source_lang', 'zh')
        target_lang = input_data.get('target_lang', 'en')
        term_table = input_data.get('term_table', [])  # æœ¯è¯­è¡¨ä¿æŠ¤
        focus_patterns = input_data.get('focus_patterns', [])  # é‡ç‚¹å…³æ³¨çš„ä½ç½®ä¿¡åº¦æ¨¡å¼ï¼ˆå…¼å®¹ï¼‰
        low_confidence_patterns = input_data.get('low_confidence_patterns', [])  # BiExtractçš„ä½ç½®ä¿¡åº¦æ¨¡å¼
        low_score_dimensions = input_data.get('low_score_dimensions', [])  # SyntaxEvalçš„ä½åˆ†ç»´åº¦
        refinement_mode = input_data.get('refinement_mode', 'full')  # full/targeted
        
        if not source_text or not target_text:
            return SyntaxTranslationResult(
                source_text=source_text,
                refined_text=target_text,
                applied_corrections=[],
                confidence=0.0,
                rule_updates=[]
            )
        
        # æ ¹æ®é…ç½®é€‰æ‹©ç”Ÿæˆæ–¹å¼
        if self.generate_candidates:
            candidates = await self._generate_refinement_candidates(
                source_text, target_text, patterns, evaluation,
                source_lang, target_lang, term_table, 
                low_confidence_patterns, low_score_dimensions, refinement_mode
            )
            if not candidates:
                # å¦‚æœå€™é€‰ç”Ÿæˆå¤±è´¥ï¼Œfallbackåˆ°å•æ¬¡ç¿»è¯‘
                logger.warning("å€™é€‰ç”Ÿæˆå¤±è´¥ï¼Œfallbackåˆ°å•æ¬¡ç¿»è¯‘")
                return await self._execute_single(
                    source_text, target_text, patterns, evaluation,
                    source_lang, target_lang, term_table, 
                    low_confidence_patterns, low_score_dimensions, refinement_mode
                )
            # è¿”å›ç¬¬ä¸€ä¸ªå€™é€‰ä½œä¸ºrefined_textï¼ŒåŒæ—¶ä¿ç•™æ‰€æœ‰å€™é€‰
            return SyntaxTranslationResult(
                source_text=source_text,
                refined_text=candidates[0],
                applied_corrections=[{"correction": "LLMç”Ÿæˆå€™é€‰", "applied": True}],
                confidence=0.8,  # é»˜è®¤ç½®ä¿¡åº¦ï¼Œå®é™…ä¼šç”±é€‰æ‹©å™¨Agentå†³å®š
                rule_updates=[],
                candidates=candidates
            )
        else:
            return await self._execute_single(
                source_text, target_text, patterns, evaluation,
                source_lang, target_lang, term_table, 
                low_confidence_patterns, low_score_dimensions, refinement_mode
            )
    
    async def _execute_single(
        self,
        source_text: str,
        target_text: str,
        patterns: List[Any],
        evaluation: Any,
        source_lang: str,
        target_lang: str,
        term_table: List[Dict[str, Any]],
        low_confidence_patterns: List[Any] = None,
        low_score_dimensions: List[Dict[str, Any]] = None,
        refinement_mode: str = 'full'
    ) -> SyntaxTranslationResult:
        """åŸæœ‰çš„å•æ¬¡æ”¹è¿›é€»è¾‘ï¼ˆæ”¯æŒé’ˆå¯¹æ€§æ”¹è¿›ï¼‰"""
        # æ³¨é‡Šï¼šç§»é™¤äº†æ—©æœŸé€€å‡ºé€»è¾‘ï¼Œå¼ºåˆ¶å°è¯•å¥æ³•æ”¹è¿›
        # å³ä½¿è¯„ä¼°åˆ†æ•°é«˜æˆ–æ²¡æœ‰æ˜ç¡®é—®é¢˜ï¼Œä¹Ÿè®©LLMå°è¯•æ”¹è¿›
        
        if low_confidence_patterns is None:
            low_confidence_patterns = []
        if low_score_dimensions is None:
            low_score_dimensions = []
        
        # æ„å»ºæœ¯è¯­ä¿æŠ¤æç¤º
        term_protection = ""
        if term_table:
            term_pairs = [f"ã€Œ{t.get('source', '')}ã€â†’ã€Œ{t.get('target', '')}ã€" for t in term_table[:10]]
            term_protection = f"""
**æœ¯è¯­è¡¨ä¿æŠ¤ï¼ˆä¸¥æ ¼éµå®ˆï¼‰**ï¼š
ä»¥ä¸‹æœ¯è¯­ç¿»è¯‘å·²ç»éªŒè¯ï¼Œ**ç»å¯¹ä¸å¯æ”¹åŠ¨**ï¼š
{', '.join(term_pairs)}

ä¿®æ”¹æ—¶å¿…é¡»ä¿æŒè¿™äº›æœ¯è¯­çš„åŸæœ‰è¯‘æ³•ã€‚
"""
        
        # æ ¹æ®refinement_modeå’Œé—®é¢˜åˆ—è¡¨æ„å»ºä¸åŒçš„æŒ‡å¯¼ä¿¡æ¯
        if refinement_mode == 'targeted' and (low_confidence_patterns or low_score_dimensions):
            problem_summary = []
            if low_confidence_patterns:
                problem_summary.append(f"{len(low_confidence_patterns)} ä¸ªä½ç½®ä¿¡åº¦å¥æ³•æ¨¡å¼ï¼ˆ< 0.9ï¼‰")
            if low_score_dimensions:
                problem_summary.append(f"{len(low_score_dimensions)} ä¸ªä½åˆ†ç»´åº¦ï¼ˆ< 0.9ï¼‰")
            
            mode_instruction = f"""
**ğŸ¯ é’ˆå¯¹æ€§æ”¹è¿›æ¨¡å¼ï¼ˆTargeted Refinementï¼‰**

æ£€æµ‹åˆ°éœ€è¦é‡ç‚¹æ”¹è¿›çš„é—®é¢˜ï¼š{', '.join(problem_summary)}
å…¶ä»–éƒ¨åˆ†è´¨é‡è‰¯å¥½ï¼Œæ— éœ€è°ƒæ•´ã€‚

**ä¼˜å…ˆçº§**ï¼š
1. ğŸ”´ **é¦–è¦ä»»åŠ¡**ï¼šé‡ç‚¹æ”¹è¿›ä¸‹åˆ—æ ‡è®°çš„é—®é¢˜
2. âœ… å…¶ä»–éƒ¨åˆ†ï¼šä¿æŒåŸæ ·ï¼ˆå·²ç»è¶³å¤Ÿå¥½ï¼‰
3. ğŸ”’ æœ¯è¯­ä¿æŠ¤ï¼šç»å¯¹ä¸æ”¹åŠ¨å·²éªŒè¯çš„æœ¯è¯­

**éœ€è¦é‡ç‚¹å…³æ³¨çš„é—®é¢˜**ï¼š
"""
            # æ·»åŠ ä½ç½®ä¿¡åº¦æ¨¡å¼è¯¦æƒ…
            if low_confidence_patterns:
                mode_instruction += f"\nğŸ“Œ **BiExtractè¯†åˆ«çš„ä½ç½®ä¿¡åº¦æ¨¡å¼** ({len(low_confidence_patterns)}ä¸ª):\n"
                for i, p in enumerate(low_confidence_patterns[:5], 1):
                    sp = p.source_pattern if hasattr(p, 'source_pattern') else p.get('source_pattern', '')
                    tp = p.target_pattern if hasattr(p, 'target_pattern') else p.get('target_pattern', '')
                    conf = p.confidence if hasattr(p, 'confidence') else p.get('confidence', 0.0)
                    mode_instruction += f"   {i}. {sp} â†’ {tp} (ç½®ä¿¡åº¦: {conf:.2f}) - éœ€è¦éªŒè¯æ”¹è¿›\n"
                if len(low_confidence_patterns) > 5:
                    mode_instruction += f"   ... è¿˜æœ‰ {len(low_confidence_patterns) - 5} ä¸ª\n"
            
            # æ·»åŠ ä½åˆ†ç»´åº¦è¯¦æƒ…
            if low_score_dimensions:
                mode_instruction += f"\nğŸ“Œ **SyntaxEvalè¯†åˆ«çš„ä½åˆ†ç»´åº¦** ({len(low_score_dimensions)}ä¸ª):\n"
                for dim in low_score_dimensions:
                    dim_name = dim['dimension']
                    dim_score = dim['score']
                    dim_issues = dim['issues']
                    
                    dim_cn = {
                        'modality': 'æƒ…æ€åŠ¨è¯',
                        'connective': 'è¿æ¥è¯',
                        'conditional': 'æ¡ä»¶å¥',
                        'passive_voice': 'è¢«åŠ¨è¯­æ€'
                    }.get(dim_name, dim_name)
                    
                    mode_instruction += f"   - {dim_cn}: {dim_score:.2f}\n"
                    if dim_issues:
                        for issue in dim_issues[:2]:
                            problem = issue.get('problem', '')
                            if problem:
                                mode_instruction += f"      âš ï¸  {problem}\n"
                        if len(dim_issues) > 2:
                            mode_instruction += f"      ... è¿˜æœ‰ {len(dim_issues) - 2} ä¸ªé—®é¢˜\n"
        else:
            mode_instruction = """
**å…¨é¢æ”¹è¿›æ¨¡å¼ï¼ˆFull Refinementï¼‰**

éœ€è¦å…¨é¢æ£€æŸ¥å¹¶æ”¹è¿›ç¿»è¯‘çš„å¥æ³•è¡¨è¾¾ã€‚
"""
        
        # ä½¿ç”¨LLMæ•´åˆå¥æ³•ä¿®æ­£ï¼ˆåº”ç”¨å¥æ³•æ¨¡å¼ï¼‰
        messages = [
            {
                "role": "system",
                "content": f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ³•å¾‹å¥æ³•ç¿»è¯‘ä¸“å®¶ã€‚ä½ çš„ä»»åŠ¡æ˜¯**åº”ç”¨æå–çš„å¥æ³•æ¨¡å¼æ¥æ”¹è¿›ç¿»è¯‘**ã€‚

{mode_instruction}

**æ”¹è¿›åŸåˆ™**ï¼š
1. **åº”ç”¨å¥æ³•æ¨¡å¼**ï¼šä¼˜å…ˆåº”ç”¨æå–å‡ºçš„å¥æ³•æ¨¡å¼æ¥ä¼˜åŒ–è¡¨è¾¾
2. **ä¿®æ­£å¥æ³•é—®é¢˜**ï¼šä¿®æ­£è¯„ä¼°ä¸­æŒ‡å‡ºçš„å¥æ³•ä¸ä¸€è‡´ï¼ˆissuesï¼‰
3. **ä¿æŒæœ¯è¯­ä¸å˜**ï¼šç»å¯¹ä¸æ”¹åŠ¨æœ¯è¯­è¡¨ä¸­å·²éªŒè¯çš„è¯‘æ³•
4. **ä¿æŒè¯­ä¹‰å‡†ç¡®**ï¼šæ”¹è¿›å¥æ³•çš„åŒæ—¶ä¿æŒåŸæ„

**å¯ä»¥æ”¹è¿›çš„æ–¹é¢**ï¼š
- æ ¹æ®æ¨¡å¼è°ƒæ•´æƒ…æ€åŠ¨è¯çš„è¡¨è¾¾ï¼ˆå¦‚shall/must/shouldçš„é€‰æ‹©ï¼‰
- æ ¹æ®æ¨¡å¼ä¼˜åŒ–è¿æ¥è¯çš„ä½¿ç”¨ï¼ˆå¦‚and/or/butçš„è¡¨è¾¾ï¼‰
- æ ¹æ®æ¨¡å¼è°ƒæ•´æ¡ä»¶é€»è¾‘çš„è¡¨è¾¾æ–¹å¼
- æ ¹æ®æ¨¡å¼ç»Ÿä¸€å¥æ³•ç»“æ„çš„é£æ ¼

{term_protection}

è¿”å›JSONæ ¼å¼ï¼š
{{
    "refined_text": "æ”¹è¿›åçš„ç¿»è¯‘ï¼ˆåº”ç”¨å¥æ³•æ¨¡å¼åçš„ç»“æœï¼‰",
    "applied_corrections": [
        {{"correction": "åº”ç”¨çš„å¥æ³•æ”¹è¿›", "applied": true}}
    ],
    "confidence": 0.9,
    "rule_updates": []
}}"""
            },
            {
                "role": "user",
                "content": f"""è¯·å¯¹ä»¥ä¸‹{source_lang}åˆ°{target_lang}çš„æ³•å¾‹ç¿»è¯‘è¿›è¡Œå¥æ³•æ”¹è¿›ï¼š

æºæ–‡æœ¬ï¼š{source_text}

å½“å‰ç¿»è¯‘ï¼š{target_text}

{self._format_evaluation_and_patterns(patterns, evaluation, low_confidence_patterns)}

**ä»»åŠ¡**ï¼š
1. ä»”ç»†åˆ†ææå–çš„å¥æ³•æ¨¡å¼ï¼ˆpatternsï¼‰
{"2. ğŸ”´ **é‡ç‚¹å…³æ³¨**ï¼šä¼˜å…ˆæ”¹è¿›ä¸Šé¢æ ‡è®°çš„ã€ä½ç½®ä¿¡åº¦æ¨¡å¼ã€‘å’Œã€ä½åˆ†ç»´åº¦é—®é¢˜ã€‘" if (low_confidence_patterns or low_score_dimensions) else "2. æ ¹æ®è¿™äº›æ¨¡å¼æ”¹è¿›å½“å‰ç¿»è¯‘çš„å¥æ³•è¡¨è¾¾"}
3. ä¿®æ­£è¯„ä¼°ä¸­æŒ‡å‡ºçš„å¥æ³•é—®é¢˜ï¼ˆissuesï¼‰
4. ä¸¥æ ¼ä¿æŠ¤æœ¯è¯­è¡¨ä¸­çš„è¯‘æ³•

è¯·è¿”å›æ”¹è¿›åçš„ç¿»è¯‘ã€‚"""
            }
        ]
        
        try:
            result = await self.call_llm_json(messages)
            
            refined_text = result.get('refined_text', target_text)
            
            # å®‰å…¨æ£€æŸ¥ï¼šè‹¥æ”¹å†™åä¸ºç©ºæˆ–è¿‡çŸ­ï¼Œå›é€€åˆ°åŸè¯‘æ–‡
            if not refined_text or not refined_text.strip():
                logger.warning("Refined text is empty, falling back to original")
                refined_text = target_text
            elif len(refined_text.strip()) < len(target_text.strip()) * 0.5:
                logger.warning(f"Refined text too short ({len(refined_text)} vs {len(target_text)}), falling back")
                refined_text = target_text
            
            return SyntaxTranslationResult(
                source_text=source_text,
                refined_text=refined_text,
                applied_corrections=result.get('applied_corrections', []),
                confidence=result.get('confidence', 0.0),
                rule_updates=result.get('rule_updates', [])
            )
        except Exception as e:
            logger.error(f"Syntax translation failed: {e}")
            return SyntaxTranslationResult(
                source_text=source_text,
                refined_text=target_text,
                applied_corrections=[],
                confidence=0.0,
                rule_updates=[]
            )
    
    def _format_evaluation_and_patterns(self, patterns: List[Any], evaluation: Any, focus_patterns: List[Any] = None) -> str:
        """æ ¼å¼åŒ–è¯„ä¼°ç»“æœå’Œå¥æ³•æ¨¡å¼ï¼ˆæ”¯æŒæ ‡è®°ä½ç½®ä¿¡åº¦æ¨¡å¼ï¼‰"""
        if focus_patterns is None:
            focus_patterns = []
        
        # æ„å»ºfocus_patternsçš„IDé›†åˆï¼ˆç”¨äºå¿«é€ŸæŸ¥æ‰¾ï¼‰
        focus_ids = set()
        for fp in focus_patterns:
            if hasattr(fp, 'source_pattern'):
                focus_ids.add(fp.source_pattern)
            elif isinstance(fp, dict):
                focus_ids.add(fp.get('source_pattern', ''))
        
        parts = []
        
        # 1. è¯„ä¼°ç»“æœ
        if evaluation:
            parts.append("ã€è¯„ä¼°ç»“æœã€‘")
            parts.append(f"æ€»åˆ†: {evaluation.overall_score:.2f}")
            parts.append(f"- æƒ…æ€åŠ¨è¯ä¿çœŸåº¦: {evaluation.modality_preservation:.2f}")
            parts.append(f"- è¿æ¥è¯ä¸€è‡´æ€§: {evaluation.connective_consistency:.2f}")
            parts.append(f"- æ¡ä»¶é€»è¾‘ç»´æŠ¤: {evaluation.conditional_logic:.2f}")
            
            if evaluation.issues:
                parts.append("\nå‘ç°çš„é—®é¢˜ï¼š")
                for issue in evaluation.issues:
                    parts.append(f"- {issue}")
            
            if evaluation.recommendations:
                parts.append("\næ”¹è¿›å»ºè®®ï¼š")
                for rec in evaluation.recommendations:
                    parts.append(f"- {rec}")
        
        # 2. å¥æ³•æ¨¡å¼ï¼ˆé‡ç‚¹æ ‡è®°ä½ç½®ä¿¡åº¦æ¨¡å¼ï¼‰
        if patterns:
            if focus_patterns:
                parts.append("\nã€è¯†åˆ«çš„å¥æ³•æ¨¡å¼ã€‘ï¼ˆğŸ”´ = ä½ç½®ä¿¡åº¦ï¼Œéœ€é‡ç‚¹æ”¹è¿›ï¼‰")
            else:
                parts.append("\nã€è¯†åˆ«çš„å¥æ³•æ¨¡å¼ã€‘")
                
            for pattern in patterns[:10]:  # æœ€å¤šæ˜¾ç¤º10ä¸ªæ¨¡å¼
                source_pattern = pattern.source_pattern if hasattr(pattern, 'source_pattern') else pattern.get('source_pattern', '')
                target_pattern = pattern.target_pattern if hasattr(pattern, 'target_pattern') else pattern.get('target_pattern', '')
                modality_type = pattern.modality_type if hasattr(pattern, 'modality_type') else pattern.get('modality_type', '')
                confidence = pattern.confidence if hasattr(pattern, 'confidence') else pattern.get('confidence', 0.0)
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯éœ€è¦é‡ç‚¹å…³æ³¨çš„æ¨¡å¼
                is_focus = source_pattern in focus_ids
                prefix = "ğŸ”´ ã€ä½ç½®ä¿¡åº¦ã€‘" if is_focus else ""
                
                parts.append(f"{prefix}- {source_pattern} â†’ {target_pattern}")
                parts.append(f"  ç±»å‹: {modality_type}, ç½®ä¿¡åº¦: {confidence:.2f}")
            
            if len(patterns) > 10:
                parts.append(f"... è¿˜æœ‰ {len(patterns) - 10} ä¸ªæ¨¡å¼")
        
        if not parts:
            return "æ— è¯„ä¼°ç»“æœå’Œå¥æ³•æ¨¡å¼"
        
        return "\n".join(parts)
    
    async def _generate_refinement_candidates(
        self,
        source_text: str,
        target_text: str,
        patterns: List[Any],
        evaluation: Any,
        source_lang: str,
        target_lang: str,
        term_table: List[Dict[str, Any]],
        low_confidence_patterns: List[Any] = None,
        low_score_dimensions: List[Dict[str, Any]] = None,
        refinement_mode: str = 'full'
    ) -> List[str]:
        """ç”Ÿæˆå¤šä¸ªå¥æ³•æ”¹è¿›å€™é€‰ï¼ˆæ”¯æŒé’ˆå¯¹æ€§æ”¹è¿›ï¼‰"""
        if low_confidence_patterns is None:
            low_confidence_patterns = []
        if low_score_dimensions is None:
            low_score_dimensions = []
        # æ„å»ºæœ¯è¯­ä¿æŠ¤æç¤º
        term_protection = ""
        if term_table:
            term_pairs = [f"ã€Œ{t.get('source', '')}ã€â†’ã€Œ{t.get('target', '')}ã€" for t in term_table[:10]]
            term_protection = f"""
**æœ¯è¯­è¡¨ä¿æŠ¤ï¼ˆä¸¥æ ¼éµå®ˆï¼‰**ï¼š
ä»¥ä¸‹æœ¯è¯­ç¿»è¯‘å·²ç»éªŒè¯ï¼Œ**ç»å¯¹ä¸å¯æ”¹åŠ¨**ï¼š
{', '.join(term_pairs)}

ä¿®æ”¹æ—¶å¿…é¡»ä¿æŒè¿™äº›æœ¯è¯­çš„åŸæœ‰è¯‘æ³•ã€‚
"""
        
        # æ ¹æ®refinement_modeæ„å»ºä¸åŒçš„æŒ‡å¯¼ä¿¡æ¯
        if refinement_mode == 'targeted' and (low_confidence_patterns or low_score_dimensions):
            problem_summary = []
            if low_confidence_patterns:
                problem_summary.append(f"{len(low_confidence_patterns)} ä¸ªä½ç½®ä¿¡åº¦å¥æ³•æ¨¡å¼ï¼ˆ< 0.9ï¼‰")
            if low_score_dimensions:
                problem_summary.append(f"{len(low_score_dimensions)} ä¸ªä½åˆ†ç»´åº¦ï¼ˆ< 0.9ï¼‰")
            
            mode_instruction = f"""
**ğŸ¯ é’ˆå¯¹æ€§æ”¹è¿›æ¨¡å¼ï¼ˆTargeted Refinementï¼‰**

æ£€æµ‹åˆ°éœ€è¦é‡ç‚¹æ”¹è¿›çš„é—®é¢˜ï¼š{', '.join(problem_summary)}

**ä¼˜å…ˆçº§**ï¼š
1. ğŸ”´ **é¦–è¦ä»»åŠ¡**ï¼šåœ¨æ¯ä¸ªå€™é€‰ä¸­ï¼Œé‡ç‚¹æ”¹è¿›æ ‡è®°çš„é—®é¢˜
2. âœ… å…¶ä»–éƒ¨åˆ†ï¼šä¿æŒåŸæ ·ï¼ˆå·²ç»è¶³å¤Ÿå¥½ï¼‰
3. ğŸ”’ æœ¯è¯­ä¿æŠ¤ï¼šç»å¯¹ä¸æ”¹åŠ¨å·²éªŒè¯çš„æœ¯è¯­

**éœ€è¦é‡ç‚¹å…³æ³¨çš„é—®é¢˜**ï¼š
"""
            # æ·»åŠ ä½ç½®ä¿¡åº¦æ¨¡å¼è¯¦æƒ…
            if low_confidence_patterns:
                mode_instruction += f"\nğŸ“Œ **BiExtractè¯†åˆ«çš„ä½ç½®ä¿¡åº¦æ¨¡å¼** ({len(low_confidence_patterns)}ä¸ª):\n"
                for i, p in enumerate(low_confidence_patterns[:5], 1):
                    sp = p.source_pattern if hasattr(p, 'source_pattern') else p.get('source_pattern', '')
                    tp = p.target_pattern if hasattr(p, 'target_pattern') else p.get('target_pattern', '')
                    conf = p.confidence if hasattr(p, 'confidence') else p.get('confidence', 0.0)
                    mode_instruction += f"   {i}. {sp} â†’ {tp} (ç½®ä¿¡åº¦: {conf:.2f})\n"
            
            # æ·»åŠ ä½åˆ†ç»´åº¦è¯¦æƒ…
            if low_score_dimensions:
                mode_instruction += f"\nğŸ“Œ **SyntaxEvalè¯†åˆ«çš„ä½åˆ†ç»´åº¦** ({len(low_score_dimensions)}ä¸ª):\n"
                for dim in low_score_dimensions:
                    dim_name = dim['dimension']
                    dim_score = dim['score']
                    dim_cn = {
                        'modality': 'æƒ…æ€åŠ¨è¯',
                        'connective': 'è¿æ¥è¯',
                        'conditional': 'æ¡ä»¶å¥',
                        'passive_voice': 'è¢«åŠ¨è¯­æ€'
                    }.get(dim_name, dim_name)
                    mode_instruction += f"   - {dim_cn}: {dim_score:.2f}\n"
            
            mode_instruction += f"""
**ç”Ÿæˆç­–ç•¥**ï¼š
- å€™é€‰1ï¼šä¿å®ˆæ”¹è¿›ï¼ˆåªæ”¹æ ‡è®°çš„é—®é¢˜ï¼‰
- å€™é€‰2ï¼šé€‚åº¦æ”¹è¿›ï¼ˆæ ‡è®°é—®é¢˜+å¾®è°ƒç›¸é‚»è¡¨è¾¾ï¼‰
- å€™é€‰3ï¼šç§¯ææ”¹è¿›ï¼ˆæ ‡è®°é—®é¢˜+ä¼˜åŒ–æ•´ä½“æµç•…æ€§ï¼‰
"""
        else:
            mode_instruction = f"""
**å…¨é¢æ”¹è¿›æ¨¡å¼ï¼ˆFull Refinementï¼‰**

éœ€è¦ç”Ÿæˆ {self.num_candidates} ä¸ªä¸åŒçš„æ”¹è¿›å€™é€‰ï¼Œæ¯ä¸ªå€™é€‰åº”è¯¥ï¼š
- åœ¨ä¿æŒæœ¯è¯­ä¸å˜çš„å‰æä¸‹
- å°è¯•ä¸åŒçš„å¥æ³•ä¼˜åŒ–ç­–ç•¥
- å°è¯•ä¸åŒçš„æƒ…æ€åŠ¨è¯/è¿æ¥è¯é€‰æ‹©
- ä¿æŒè¯­ä¹‰ä½†è¡¨è¾¾ç•¥æœ‰å·®å¼‚
"""
        
        messages = [
            {
                "role": "system",
                "content": f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ³•å¾‹å¥æ³•ç¿»è¯‘ä¸“å®¶ã€‚ä½ çš„ä»»åŠ¡æ˜¯**åº”ç”¨æå–çš„å¥æ³•æ¨¡å¼æ¥æ”¹è¿›ç¿»è¯‘**ã€‚

{mode_instruction}

{term_protection}

è¾“å‡ºè¦æ±‚ï¼šè¯·ä¸¥æ ¼ä»¥jsonæ ¼å¼è¾“å‡ºï¼š
{{
    "candidates": [
        {{"refined_text": "å€™é€‰1", "confidence": 0.9}},
        {{"refined_text": "å€™é€‰2", "confidence": 0.85}},
        {{"refined_text": "å€™é€‰3", "confidence": 0.88}}
    ]
}}
"""
            },
            {
                "role": "user",
                "content": f"""è¯·å¯¹ä»¥ä¸‹{source_lang}åˆ°{target_lang}çš„æ³•å¾‹ç¿»è¯‘è¿›è¡Œå¥æ³•æ”¹è¿›ï¼ˆç”Ÿæˆ{self.num_candidates}ä¸ªå€™é€‰ï¼‰ï¼š

æºæ–‡æœ¬ï¼š{source_text}

å½“å‰ç¿»è¯‘ï¼š{target_text}

{self._format_evaluation_and_patterns(patterns, evaluation, low_confidence_patterns)}

{"ğŸ”´ **é‡ç‚¹ä»»åŠ¡**ï¼šé’ˆå¯¹ä¸Šé¢æ ‡è®°çš„ã€ä½ç½®ä¿¡åº¦æ¨¡å¼ã€‘å’Œã€ä½åˆ†ç»´åº¦é—®é¢˜ã€‘è¿›è¡Œæ”¹è¿›" if (low_confidence_patterns or low_score_dimensions) else ""}

è¯·è¿”å› {self.num_candidates} ä¸ªä¸åŒçš„æ”¹è¿›å€™é€‰ã€‚"""
            }
        ]
        
        try:
            # ä½¿ç”¨ç¨é«˜çš„temperatureå¢åŠ å¤šæ ·æ€§
            result = await self.call_llm_json(messages, temperature=0.4)
            
            candidates_data = result.get('candidates', [])
            candidates = [c.get('refined_text', '') for c in candidates_data if c.get('refined_text', '').strip()]
            
            # è¿‡æ»¤æ‰è¿‡çŸ­çš„å€™é€‰
            candidates = [c for c in candidates if len(c.strip()) >= len(target_text.strip()) * 0.5]
            
            # ğŸšª é—¨æ§æœºåˆ¶ï¼šå°†åŸæ–‡ä½œä¸ºç¬¬ä¸€ä¸ªå€™é€‰
            # è®©LLMé€‰æ‹©å™¨åˆ¤æ–­æ˜¯å¦çœŸçš„éœ€è¦ä¿®æ”¹
            eval_score = evaluation.overall_score if evaluation and hasattr(evaluation, 'overall_score') else 0.0
            candidates.insert(0, target_text)
            logger.info(f"ğŸšª é—¨æ§ï¼šåŸæ–‡å·²åŠ å…¥å€™é€‰åˆ—è¡¨ï¼ˆä½ç½®0ï¼‰ï¼Œè¯„ä¼°åˆ†æ•°: {eval_score:.2f}")
            
            if len(candidates) >= self.num_candidates:
                logger.info(f"æˆåŠŸç”Ÿæˆ {len(candidates)} ä¸ªæ”¹è¿›å€™é€‰")
                return candidates[:self.num_candidates]
            elif candidates:
                logger.warning(f"åªç”Ÿæˆäº† {len(candidates)}/{self.num_candidates} ä¸ªæœ‰æ•ˆå€™é€‰ï¼Œè¡¥å……ç”Ÿæˆ")
                # è¡¥å……ç”Ÿæˆ
                additional = await self._generate_candidates_by_multiple_calls(
                    source_text, target_text, patterns, evaluation,
                    source_lang, target_lang, term_table,
                    low_confidence_patterns, low_score_dimensions,
                    num_needed=self.num_candidates - len(candidates)
                )
                candidates.extend(additional)
                return candidates[:self.num_candidates]
            else:
                logger.warning("LLMæœªè¿”å›æœ‰æ•ˆå€™é€‰ï¼Œé™çº§ä¸ºå¤šæ¬¡è°ƒç”¨")
                return await self._generate_candidates_by_multiple_calls(
                    source_text, target_text, patterns, evaluation,
                    source_lang, target_lang, term_table,
                    low_confidence_patterns, low_score_dimensions,
                    num_needed=self.num_candidates
                )
                
        except Exception as e:
            logger.error(f"ç”Ÿæˆæ”¹è¿›å€™é€‰å¤±è´¥: {e}ï¼Œé™çº§ä¸ºå¤šæ¬¡è°ƒç”¨")
            return await self._generate_candidates_by_multiple_calls(
                source_text, target_text, patterns, evaluation,
                source_lang, target_lang, term_table,
                low_confidence_patterns, low_score_dimensions,
                num_needed=self.num_candidates
            )
    
    async def _generate_candidates_by_multiple_calls(
        self,
        source_text: str,
        target_text: str,
        patterns: List[Any],
        evaluation: Any,
        source_lang: str,
        target_lang: str,
        term_table: List[Dict[str, Any]],
        low_confidence_patterns: List[Any] = None,
        low_score_dimensions: List[Dict[str, Any]] = None,
        num_needed: int = None
    ) -> List[str]:
        """é€šè¿‡å¤šæ¬¡è°ƒç”¨LLMç”Ÿæˆä¸åŒå€™é€‰ï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰"""
        if num_needed is None:
            num_needed = self.num_candidates
        if low_confidence_patterns is None:
            low_confidence_patterns = []
        if low_score_dimensions is None:
            low_score_dimensions = []
            
        # ğŸšª é—¨æ§æœºåˆ¶ï¼šåŸæ–‡ä½œä¸ºç¬¬ä¸€ä¸ªå€™é€‰
        candidates = [target_text]
        logger.info("ğŸšª é—¨æ§ï¼šå¤‡ç”¨æ–¹æ¡ˆä¹Ÿå°†åŸæ–‡ä½œä¸ºç¬¬ä¸€ä¸ªå€™é€‰")
        temperatures = [0.1, 0.3, 0.5, 0.7, 0.9]
        
        for i, temp in enumerate(temperatures[:num_needed]):
            try:
                result = await self._execute_single(
                    source_text, target_text, patterns, evaluation,
                    source_lang, target_lang, term_table,
                    low_confidence_patterns, low_score_dimensions, 'full'
                )
                refined = result.refined_text.strip()
                if refined and len(refined) >= len(target_text.strip()) * 0.5:
                    candidates.append(refined)
                    logger.debug(f"æ¸©åº¦{temp}ç”Ÿæˆå€™é€‰{i+1}: æˆåŠŸ")
            except Exception as e:
                logger.warning(f"æ¸©åº¦{temp}ç”Ÿæˆå€™é€‰å¤±è´¥: {e}")
        
        if not candidates:
            # æœ€åçš„ä¿åº•ï¼šè¿”å›åŸæ–‡æœ¬
            candidates.append(target_text)
        
        logger.info(f"é€šè¿‡å¤šæ¬¡è°ƒç”¨ç”Ÿæˆäº† {len(candidates)} ä¸ªå€™é€‰")
        return candidates

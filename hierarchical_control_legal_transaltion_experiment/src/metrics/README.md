# æœºå™¨ç¿»è¯‘è¯„ä¼°æŒ‡æ ‡æ¨¡å—

æœ¬æ¨¡å—å®ç°äº†æœ€æ–°çš„æœºå™¨ç¿»è¯‘è¯„ä¼°æŒ‡æ ‡ï¼ˆ2024ï¼‰ï¼Œç”¨äºå…¨é¢è¯„ä¼°ç¿»è¯‘è´¨é‡ã€‚

## ğŸ“Š æ”¯æŒçš„æŒ‡æ ‡

### 1. BLEU (Bilingual Evaluation Understudy)
- **ç±»å‹**: ä¼ ç»Ÿn-gramé‡å æŒ‡æ ‡
- **èŒƒå›´**: 0-100
- **ç‰¹ç‚¹**: 
  - å¿«é€Ÿè®¡ç®—
  - åŸºäºç²¾ç¡®åŒ¹é…
  - é€‚åˆä½œä¸ºåŸºçº¿
- **ä½¿ç”¨åœºæ™¯**: å¿«é€Ÿè¯„ä¼°ã€åŸºçº¿å¯¹æ¯”

### 2. chrF / chrF++
- **ç±»å‹**: å­—ç¬¦çº§F-score
- **èŒƒå›´**: 0-100
- **ç‰¹ç‚¹**:
  - å­—ç¬¦çº§n-gram
  - ç‰¹åˆ«é€‚åˆä¸­æ–‡ã€æ—¥è¯­ç­‰è¯­è¨€
  - ä¸éœ€è¦åˆ†è¯
- **ä½¿ç”¨åœºæ™¯**: å¤šè¯­è¨€è¯„ä¼°ã€å½¢æ€ä¸°å¯Œè¯­è¨€

### 3. BERTScore
- **ç±»å‹**: åŸºäºé¢„è®­ç»ƒæ¨¡å‹çš„è¯­ä¹‰ç›¸ä¼¼åº¦
- **èŒƒå›´**: 0-1
- **ç‰¹ç‚¹**:
  - ä½¿ç”¨XLM-RoBERTaç­‰æ¨¡å‹
  - æ•æ‰è¯­ä¹‰ç›¸ä¼¼æ€§
  - æ”¯æŒå¤šè¯­è¨€
- **ä½¿ç”¨åœºæ™¯**: è¯­ä¹‰è´¨é‡è¯„ä¼°

### 4. COMET
- **ç±»å‹**: ç¥ç»ç½‘ç»œç¿»è¯‘è´¨é‡ä¼°è®¡
- **èŒƒå›´**: çº¦0-1ï¼ˆå¯èƒ½è¶…å‡ºï¼‰
- **ç‰¹ç‚¹**:
  - WMT2022æœ€ä½³æŒ‡æ ‡
  - é«˜åº¦ç›¸å…³äººç±»åˆ¤æ–­
  - éœ€è¦æºæ–‡æœ¬å’Œå‚è€ƒ
- **ä½¿ç”¨åœºæ™¯**: é«˜è´¨é‡è¯„ä¼°ã€ä¸äººç±»åˆ¤æ–­å¯¹é½

### 5. GEMBA (MQM & DA)
- **ç±»å‹**: åŸºäºLLMçš„ç¿»è¯‘è´¨é‡è¯„ä¼°
- **èŒƒå›´**: 0-100
- **å®˜æ–¹å®ç°**: [Microsoft/GEMBA](https://github.com/MicrosoftTranslator/GEMBA)
- **ä¸¤ç§æ–¹æ³•**:
  - **GEMBA-MQM**: åŸºäºMQMæ¡†æ¶çš„è¯¦ç»†é”™è¯¯æ£€æµ‹å’Œè¯„åˆ†
    - è¯†åˆ«ç¿»è¯‘é”™è¯¯å¹¶åˆ†ç±»ï¼ˆAccuracy, Fluency, Terminology, Style, Localeï¼‰
    - æ ‡æ³¨é”™è¯¯ä¸¥é‡ç¨‹åº¦ï¼ˆMinor, Major, Criticalï¼‰
    - ä½¿ç”¨MQMå…¬å¼è®¡ç®—åˆ†æ•°ï¼ˆ100åˆ†åˆ¶ï¼Œæ‰£åˆ†åˆ¶ï¼‰
  - **GEMBA-DA**: ç›´æ¥è¯„ä¼°ï¼ˆDirect Assessmentï¼‰
    - ç›´æ¥è¾“å‡º0-100çš„è´¨é‡åˆ†æ•°
    - æ›´å¿«é€Ÿï¼Œé€‚åˆæ‰¹é‡è¯„ä¼°
    - åŸºäºå‡†ç¡®æ€§ã€æµç•…æ€§ã€å……åˆ†æ€§è¯„ä¼°
- **ç‰¹ç‚¹**:
  - ä½¿ç”¨GPT-4ï¼ˆWMT2023æœ€ä½³è¯„ä¼°æŒ‡æ ‡ï¼‰
  - æœ€æ¥è¿‘äººå·¥è¯„ä¼°ï¼ˆäººç±»ç›¸å…³æ€§æœ€é«˜ï¼‰
  - æä¾›å¯è§£é‡Šçš„è¯„ä¼°ç»“æœ
- **ä½¿ç”¨åœºæ™¯**: 
  - GEMBA-MQM: è¯¦ç»†é”™è¯¯åˆ†æã€è´¨é‡è¯Šæ–­
  - GEMBA-DA: å¿«é€Ÿè´¨é‡è¯„ä¼°ã€ä¸äººç±»åˆ¤æ–­å¯¹é½

## ğŸš€ å¿«é€Ÿå¼€å§‹

### å®‰è£…ä¾èµ–

```bash
# åŸºç¡€æŒ‡æ ‡
pip install sacrebleu

# BERTScore
pip install bert-score

# COMET
pip install unbabel-comet

# æ‰€æœ‰æŒ‡æ ‡
pip install -r requirements.txt
```

### åŸºæœ¬ä½¿ç”¨

```python
from src.metrics import MetricSuite

# åˆ›å»ºæŒ‡æ ‡å¥—ä»¶
suite = MetricSuite(metrics=['bleu', 'chrf', 'bertscore', 'comet'])

# è®¡ç®—åˆ†æ•°
scores = suite.compute(
    source="åˆåŒåŒæ–¹åº”å½“éµå®ˆæœ¬åè®®çš„æ‰€æœ‰æ¡æ¬¾ã€‚",
    prediction="The parties shall comply with all terms of this agreement.",
    reference="Contracting parties must comply with all provisions of this agreement."
)

print(scores)
# è¾“å‡º: {
#   'bleu': 45.23,
#   'chrf': 67.89,
#   'bertscore_f1': 0.8234,
#   'comet': 0.7654
# }
```

### å•ä¸ªæŒ‡æ ‡ä½¿ç”¨

```python
from src.metrics import BLEUMetric, ChrFMetric, COMETMetric, GEMBAMetric

# BLEU
bleu = BLEUMetric(tokenize='zh')
score = bleu.sentence_score(prediction, reference)

# chrF++
chrf = ChrFMetric()
score = chrf.sentence_score(prediction, reference)

# COMET
comet = COMETMetric()
score = comet.sentence_score(source, prediction, reference)

# GEMBA-DA (æ¨èç”¨äºå¿«é€Ÿè¯„ä¼°)
gemba_da = GEMBAMetric(method="GEMBA-DA", model="gpt-4")
score = gemba_da.sentence_score(source, prediction, "Chinese", "English")

# GEMBA-MQM (è¯¦ç»†é”™è¯¯åˆ†æ)
gemba_mqm = GEMBAMetric(method="GEMBA-MQM", model="gpt-4")
result = gemba_mqm.compute([source], [prediction], "Chinese", "English")
print(f"åˆ†æ•°: {result['mean']}")
print(f"é”™è¯¯: {result['results'][0]['errors']}")
```

## ğŸ“ åœ¨å®éªŒä¸­ä½¿ç”¨

### æ›´æ–° metrics.py

```python
from src.metrics import MetricSuite

class LegalTranslationMetrics:
    def __init__(self):
        # åŸæœ‰çš„æ³•å¾‹ä¸“ç”¨æŒ‡æ ‡
        self.deontic_mapping = {...}
        
        # æ·»åŠ ç°ä»£MTæŒ‡æ ‡
        self.mt_metrics = MetricSuite(
            metrics=['bleu', 'chrf', 'comet'],
            lang='zh'
        )
    
    def calculate_all_metrics(self, source, target, reference, 
                             src_lang, tgt_lang, term_table):
        # æ³•å¾‹ä¸“ç”¨æŒ‡æ ‡
        legal_metrics = {
            'termbase_accuracy': self.calculate_termbase_accuracy(...),
            'deontic_preservation': self.calculate_deontic_preservation(...),
            'conditional_logic': self.calculate_conditional_logic_preservation(...)
        }
        
        # ç°ä»£MTæŒ‡æ ‡
        mt_metrics = self.mt_metrics.compute(source, target, reference)
        
        # åˆå¹¶
        return {**legal_metrics, **mt_metrics}
```

### åœ¨å®éªŒä¸­ä½¿ç”¨

```python
# run_experiment.py ä¼šè‡ªåŠ¨ä½¿ç”¨æ–°æŒ‡æ ‡
python run_experiment.py \
  --samples 50 \
  --ablations baseline terminology terminology_syntax full
```

## ğŸ¯ æŒ‡æ ‡é€‰æ‹©å»ºè®®

### å¿«é€Ÿè¯„ä¼°ï¼ˆæ¨èï¼‰
```python
suite = MetricSuite(metrics=['bleu', 'chrf'])
```
- è®¡ç®—å¿«é€Ÿ
- èµ„æºå ç”¨å°‘
- é€‚åˆå¤§è§„æ¨¡å®éªŒ

### å¹³è¡¡è¯„ä¼°ï¼ˆæ¨èï¼‰
```python
suite = MetricSuite(metrics=['bleu', 'chrf', 'comet'])
```
- åŒ…å«ä¼ ç»Ÿå’Œç¥ç»æŒ‡æ ‡
- è®¡ç®—é€Ÿåº¦é€‚ä¸­
- è¦†ç›–å¤šä¸ªç»´åº¦

### å®Œæ•´è¯„ä¼°
```python
suite = MetricSuite(
    metrics=['bleu', 'chrf', 'bertscore', 'comet', 'gemba'],
    gemba_method='GEMBA-DA'  # æˆ– 'GEMBA-MQM'
)
```
- æœ€å…¨é¢çš„è¯„ä¼°
- è®¡ç®—æ—¶é—´è¾ƒé•¿
- é€‚åˆæœ€ç»ˆè¯„ä¼°
- GEMBA-DAæ›´å¿«ï¼ŒGEMBA-MQMæä¾›è¯¦ç»†é”™è¯¯åˆ†æ

## ğŸ“Š æŒ‡æ ‡å¯¹æ¯”

| æŒ‡æ ‡ | é€Ÿåº¦ | GPU | èµ„æº | ä¸äººç±»ç›¸å…³æ€§ | é€‚ç”¨åœºæ™¯ |
|------|------|-----|------|-------------|----------|
| BLEU | âš¡âš¡âš¡ | âŒ | æ—  | â­â­ | åŸºçº¿ã€å¿«é€Ÿ |
| chrF++ | âš¡âš¡âš¡ | âŒ | æ—  | â­â­â­ | å¤šè¯­è¨€ |
| BERTScore | âš¡âš¡ | âœ… | 1.4GB | â­â­â­â­ | è¯­ä¹‰è¯„ä¼° |
| COMET | âš¡âš¡ | âœ… | 2.3GB | â­â­â­â­â­ | WMT2022æœ€ä½³ |
| GEMBA-DA | âš¡ | âŒ | GPT-4 | â­â­â­â­â­ | WMT2023æœ€ä½³ |
| GEMBA-MQM | âš¡ | âŒ | GPT-4 | â­â­â­â­â­ | é”™è¯¯è¯Šæ–­ |

## ğŸ”§ é«˜çº§é…ç½®

### è‡ªå®šä¹‰COMETæ¨¡å‹

```python
from src.metrics import COMETMetric

# ä½¿ç”¨ä¸åŒçš„COMETæ¨¡å‹
comet = COMETMetric(
    model_name="Unbabel/XCOMET-XXL",  # æœ€å¤§æ¨¡å‹
    gpus=1  # ä½¿ç”¨GPU
)
```

### è‡ªå®šä¹‰BERTScoreæ¨¡å‹

```python
from src.metrics import BERTScoreMetric

# ä¸­æ–‡ç‰¹åŒ–æ¨¡å‹
bertscore = BERTScoreMetric(
    model_type="bert-base-chinese",
    lang="zh"
)
```

### ä½¿ç”¨GEMBAæŒ‡æ ‡

```python
from src.metrics import GEMBAMetric

# æ–¹æ³•1: GEMBA-DA (æ¨èï¼Œæ›´å¿«é€Ÿ)
gemba_da = GEMBAMetric(
    method="GEMBA-DA",
    model="gpt-4",
    temperature=0.1  # å®˜æ–¹æ¨è
)

score = gemba_da.sentence_score(
    source="åˆåŒåŒæ–¹åº”å½“éµå®ˆæœ¬åè®®çš„æ‰€æœ‰æ¡æ¬¾ã€‚",
    prediction="The parties shall comply with all terms.",
    source_lang="Chinese",
    target_lang="English"
)
print(f"GEMBA-DA: {score:.2f}/100")

# æ–¹æ³•2: GEMBA-MQM (è¯¦ç»†é”™è¯¯åˆ†æ)
gemba_mqm = GEMBAMetric(
    method="GEMBA-MQM",
    model="gpt-4"
)

result = gemba_mqm.compute(
    sources=["åˆåŒåŒæ–¹åº”å½“éµå®ˆæœ¬åè®®çš„æ‰€æœ‰æ¡æ¬¾ã€‚"],
    predictions=["The parties shall comply with all terms."],
    source_lang="Chinese",
    target_lang="English"
)

print(f"GEMBA-MQM: {result['mean']:.2f}/100")
print(f"é”™è¯¯è¯¦æƒ…: {result['results'][0]['errors']}")
print(f"é”™è¯¯ç»Ÿè®¡: {result['results'][0]['error_count']}")
```

### æ‰¹é‡è®¡ç®—

```python
sources = ["æ–‡æœ¬1", "æ–‡æœ¬2", "æ–‡æœ¬3"]
predictions = ["ç¿»è¯‘1", "ç¿»è¯‘2", "ç¿»è¯‘3"]
references = ["å‚è€ƒ1", "å‚è€ƒ2", "å‚è€ƒ3"]

# æ‰¹é‡COMET
comet = COMETMetric()
result = comet.compute(sources, predictions, references)
print(f"ç³»ç»Ÿçº§COMET: {result['system_score']:.4f}")

# æ‰¹é‡GEMBA-DA
gemba = GEMBAMetric(method="GEMBA-DA")
result = gemba.compute(sources, predictions, "Chinese", "English")
print(f"ç³»ç»Ÿçº§GEMBA-DA: {result['system_score']:.2f}/100")
```

## âš ï¸ æ³¨æ„äº‹é¡¹

1. **é¦–æ¬¡ä½¿ç”¨**: BERTScoreå’ŒCOMETé¦–æ¬¡ä½¿ç”¨ä¼šä¸‹è½½æ¨¡å‹ï¼ˆè¾ƒå¤§ï¼‰
   - **å·²å†…ç½®é•œåƒåŠ é€Ÿ**: é»˜è®¤ä½¿ç”¨ `hf-mirror.com` åŠ é€Ÿä¸‹è½½
   - xlm-roberta-large: ~1.4GB
   - wmt22-comet-da: ~2.3GB
2. **GPUåŠ é€Ÿ**: BERTScoreå’ŒCOMETæ”¯æŒGPUï¼Œå»ºè®®ä½¿ç”¨ä»¥æé«˜é€Ÿåº¦
3. **å†…å­˜å ç”¨**: COMET-XXLç­‰å¤§æ¨¡å‹éœ€è¦è¾ƒå¤šå†…å­˜
4. **APIè°ƒç”¨**: GEMBAæŒ‡æ ‡ä½¿ç”¨GPT-4 APIï¼Œä¼šäº§ç”Ÿè´¹ç”¨
   - GEMBA-DA: æ¯æ¡çº¦500-800 tokens
   - GEMBA-MQM: æ¯æ¡çº¦800-1200 tokensï¼ˆæ›´è¯¦ç»†ï¼‰
5. **è¯­è¨€æ”¯æŒ**: 
   - GEMBAæ”¯æŒä»»ä½•è¯­è¨€å¯¹ï¼ˆé€šè¿‡è¯­è¨€åç§°æŒ‡å®šï¼‰
   - å…¶ä»–æŒ‡æ ‡ç¡®ä¿ä¸ºç›®æ ‡è¯­è¨€é€‰æ‹©åˆé€‚çš„æ¨¡å‹
6. **æ¸©åº¦å‚æ•°**: GEMBAå®˜æ–¹æ¨ètemperature=0.1ï¼ˆå·²é»˜è®¤è®¾ç½®ï¼‰
7. **é•œåƒåŠ é€Ÿ**: 
   - å›½å†…ç”¨æˆ·é»˜è®¤å¯ç”¨ HF é•œåƒåŠ é€Ÿï¼ˆ`use_hf_mirror=True`ï¼‰
   - å¯é€šè¿‡å‚æ•°ç¦ç”¨ï¼š`BERTScoreMetric(use_hf_mirror=False)`

## ğŸ“š å‚è€ƒæ–‡çŒ®

- **BLEU**: [Papineni et al., 2002](https://aclanthology.org/P02-1040/) - ä¼ ç»Ÿn-gramç²¾ç¡®åŒ¹é…
- **chrF**: [PopoviÄ‡, 2015](https://aclanthology.org/W15-3049/) - å­—ç¬¦çº§F-score
- **BERTScore**: [Zhang et al., 2020](https://arxiv.org/abs/1904.09675) - åŸºäºBERTçš„è¯­ä¹‰ç›¸ä¼¼åº¦
- **COMET**: [Rei et al., 2020](https://arxiv.org/abs/2009.09025) - WMT2022æœ€ä½³æŒ‡æ ‡
- **GEMBA-DA**: [Kocmi & Federmann, 2023](https://aclanthology.org/2023.eamt-1.19) - "Large Language Models Are State-of-the-Art Evaluators of Translation Quality"
- **GEMBA-MQM**: [Kocmi & Federmann, 2023](https://arxiv.org/abs/2310.13988) - "GEMBA-MQM: Detecting Translation Quality Error Spans with GPT-4"
- **å®˜æ–¹å®ç°**: [Microsoft/GEMBA](https://github.com/MicrosoftTranslator/GEMBA)

## ğŸ› ï¸ æ•…éšœæ’æŸ¥

### é—®é¢˜ï¼šæ¨¡å‹ä¸‹è½½é€Ÿåº¦æ…¢ï¼ˆæ¨èé…ç½®ï¼‰

**æ–¹æ³•1: ä½¿ç”¨å†…ç½®é•œåƒï¼ˆæ¨èï¼Œè‡ªåŠ¨å¯ç”¨ï¼‰**
```python
# æ‰€æœ‰æŒ‡æ ‡é»˜è®¤å·²å¯ç”¨HFé•œåƒåŠ é€Ÿ
from src.metrics import BERTScoreMetric, COMETMetric, MetricSuite

# è‡ªåŠ¨ä½¿ç”¨ hf-mirror.com é•œåƒ
bertscore = BERTScoreMetric()  # use_hf_mirror=True é»˜è®¤
comet = COMETMetric()  # use_hf_mirror=True é»˜è®¤
suite = MetricSuite()  # use_hf_mirror=True é»˜è®¤
```

**æ–¹æ³•2: æ‰‹åŠ¨è®¾ç½®ç¯å¢ƒå˜é‡**
```bash
# åœ¨å‘½ä»¤è¡Œä¸­è®¾ç½®ï¼ˆä¸´æ—¶ï¼‰
export HF_ENDPOINT=https://hf-mirror.com

# æˆ–æ·»åŠ åˆ° ~/.bashrc æˆ– ~/.zshrcï¼ˆæ°¸ä¹…ï¼‰
echo 'export HF_ENDPOINT=https://hf-mirror.com' >> ~/.bashrc
source ~/.bashrc

# ä½¿ç”¨é…ç½®è„šæœ¬
source setup_hf_mirror.sh
```

**æ–¹æ³•3: åœ¨ä»£ç ä¸­è®¾ç½®**
```python
import os
os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'
```

### é—®é¢˜ï¼šCOMETæ¨¡å‹ä¸‹è½½å¤±è´¥
```bash
# ä½¿ç”¨é•œåƒæ‰‹åŠ¨ä¸‹è½½
export HF_ENDPOINT=https://hf-mirror.com
python -c "from comet import download_model; download_model('Unbabel/wmt22-comet-da')"
```

### é—®é¢˜ï¼šBERTScoreé€Ÿåº¦æ…¢
```python
# ä½¿ç”¨æ›´å°çš„æ¨¡å‹
bertscore = BERTScoreMetric(model_type="bert-base-multilingual-cased")
```

### é—®é¢˜ï¼šå†…å­˜ä¸è¶³
```python
# å‡å°‘batch size
comet = COMETMetric(batch_size=4, gpus=0)  # ä½¿ç”¨CPU
```

### é—®é¢˜ï¼šGEMBA APIè°ƒç”¨å¤±è´¥
```python
# ç¡®ä¿è®¾ç½®äº†OpenAI APIå¯†é’¥
# åœ¨ .env æ–‡ä»¶ä¸­:
# OPENAI_API_KEY=your_api_key

# æˆ–åœ¨ä»£ç ä¸­:
import os
os.environ['OPENAI_API_KEY'] = 'your_api_key'
```

### é—®é¢˜ï¼šGEMBAè¯„ä¼°é€Ÿåº¦æ…¢
```python
# æ–¹æ¡ˆ1: ä½¿ç”¨GEMBA-DAè€ŒéGEMBA-MQMï¼ˆæ›´å¿«ï¼‰
gemba = GEMBAMetric(method="GEMBA-DA")

# æ–¹æ¡ˆ2: å‡å°‘æ ·æœ¬æ•°é‡
# æ–¹æ¡ˆ3: ä½¿ç”¨å¼‚æ­¥æ‰¹é‡è¯„ä¼°
results = await gemba.compute_async(sources, predictions, "Chinese", "English")
```

## ğŸ’¡ æœ€ä½³å®è·µ

### æŒ‡æ ‡ç»„åˆæ¨è

1. **å¼€å‘é˜¶æ®µ** (å¿«é€Ÿè¿­ä»£)
   ```python
   suite = MetricSuite(metrics=['bleu', 'chrf'])
   ```

2. **éªŒè¯é˜¶æ®µ** (å¹³è¡¡è´¨é‡)
   ```python
   suite = MetricSuite(metrics=['bleu', 'chrf', 'comet'])
   ```

3. **æœ€ç»ˆè¯„ä¼°** (å®Œæ•´åˆ†æ)
   ```python
   suite = MetricSuite(
       metrics=['bleu', 'chrf', 'comet', 'gemba'],
       gemba_method='GEMBA-DA'
   )
   ```

4. **é”™è¯¯åˆ†æ** (è¯¦ç»†è¯Šæ–­)
   ```python
   gemba_mqm = GEMBAMetric(method="GEMBA-MQM")
   # æä¾›è¯¦ç»†çš„é”™è¯¯åˆ†ç±»å’Œä¸¥é‡ç¨‹åº¦
   ```

### WMTæ ‡å‡†ç»„åˆ

æ ¹æ®WMT2023è¯„ä¼°ä»»åŠ¡ï¼š
```python
# å®˜æ–¹æ¨èçš„æŒ‡æ ‡ç»„åˆ
suite = MetricSuite(metrics=['comet', 'gemba'])
# COMET: ç¥ç»ç½‘ç»œè¯„ä¼°
# GEMBA-DA: LLMè¯„ä¼°
# ä¸¤è€…ç»“åˆå¯è¾¾åˆ°æœ€é«˜çš„äººç±»åˆ¤æ–­ç›¸å…³æ€§
```

## ğŸ“ æ”¯æŒ

å¦‚æœ‰é—®é¢˜ï¼Œè¯·æŸ¥çœ‹ï¼š
- [å®˜æ–¹æ–‡æ¡£](../../README.md)
- [Issue tracker](https://github.com/MicrosoftTranslator/GEMBA/issues)
- [GEMBAå®˜æ–¹ä»“åº“](https://github.com/MicrosoftTranslator/GEMBA)


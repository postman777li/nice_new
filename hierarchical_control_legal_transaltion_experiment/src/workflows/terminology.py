"""
æœ¯è¯­å·¥ä½œæµ - ä¸‰æ­¥æœ¯è¯­æå–-éªŒè¯-ç¿»è¯‘è¿‡ç¨‹
1. Mono-Extract Agent: è¯†åˆ«å’Œæå–å…³é”®æ³•å¾‹æœ¯è¯­
2. Search + Evaluate: ä»æœ¯è¯­åº“æ£€ç´¢å€™é€‰ç¿»è¯‘å¹¶è¯„ä¼°è´¨é‡
3. Translation Agent: åŸºäºéªŒè¯æœ¯è¯­è¡¨ç”Ÿæˆåˆå§‹ç¿»è¯‘
"""
from typing import Dict, Any, Optional, TYPE_CHECKING
from ..agents.terminology.mono_extract import MonoExtractAgent
from ..agents.terminology.search import SearchAgent
from ..agents.terminology.evaluate import EvaluateAgent
from ..agents.terminology.translation import TranslationAgent
from ..agents.utils import get_global_control_config

if TYPE_CHECKING:
    from ..agents.utils import TranslationControlConfig


async def run_terminology_workflow(
    text: str,
    src_lang: str,
    tgt_lang: str,
    use_termbase: bool = True,
    db_path: str = 'terms.db',
    verbose: bool = False,
    selection_config: Optional['TranslationControlConfig'] = None
) -> Dict[str, Any]:
    """è¿è¡Œæœ¯è¯­å·¥ä½œæµï¼šä¸‰æ­¥æœ¯è¯­æå–-éªŒè¯-ç¿»è¯‘è¿‡ç¨‹
    
    Args:
        text: æºæ–‡æœ¬
        src_lang: æºè¯­è¨€
        tgt_lang: ç›®æ ‡è¯­è¨€
        use_termbase: æ˜¯å¦ä½¿ç”¨æœ¯è¯­åº“
        db_path: æœ¯è¯­åº“è·¯å¾„
        verbose: æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
    
    Returns:
        åŒ…å«ç¿»è¯‘ç»“æœå’Œæœ¯è¯­è¡¨çš„å­—å…¸
    """
    try:
        # 1) Mono-Extract Agent: è¯†åˆ«å’Œæå–å…³é”®æ³•å¾‹æœ¯è¯­
        if verbose:
            print(f"   ğŸ“ æå–æœ¯è¯­...")
        
        mono_agent = MonoExtractAgent(locale=src_lang)
        extracted_terms = await mono_agent.execute({
            "text": text,
            "domain": "legal"
        }, None)
        
        if verbose:
            print(f"   æå–åˆ° {len(extracted_terms)} ä¸ªæœ¯è¯­")
            if extracted_terms:
                print(f"\n   ã€è¯¦ç»†ã€‘æå–çš„æœ¯è¯­:")
                for i, term in enumerate(extracted_terms[:10], 1):
                    conf = getattr(term, 'confidence', 'N/A')
                    print(f"   {i}. {term.term} (ç½®ä¿¡åº¦: {conf})")
                if len(extracted_terms) > 10:
                    print(f"   ... è¿˜æœ‰ {len(extracted_terms) - 10} ä¸ªæœ¯è¯­")
        
        term_table = []
        
        # 2) Search + Evaluate: å¦‚æœä½¿ç”¨æœ¯è¯­åº“ï¼Œæ£€ç´¢å¹¶è¯„ä¼°æœ¯è¯­ç¿»è¯‘
        if use_termbase and extracted_terms:
            # 2a) Search Agent: ä»æœ¯è¯­åº“æ£€ç´¢å€™é€‰ç¿»è¯‘
            if verbose:
                print(f"   ğŸ” ä»æœ¯è¯­åº“æ£€ç´¢...")
            
            search_agent = SearchAgent(locale=src_lang, db_path=db_path)
            search_results = await search_agent.execute({
                "terms": [term.term for term in extracted_terms],
                "source_lang": src_lang,
                "target_lang": tgt_lang,
                "domain": ""  # ä¸é™åˆ¶domainï¼Œæœç´¢æ‰€æœ‰æ³•å¾‹æœ¯è¯­
            }, None)
            
            # æ„å»ºå€™é€‰æœ¯è¯­è¡¨ï¼ˆåŒ…å«ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼‰
            candidate_table = [
                {
                    'source': r.term,
                    'target': r.translation,
                    'confidence': r.confidence,
                    'context': r.context  # æ·»åŠ åŸå§‹ä¸Šä¸‹æ–‡ï¼Œç”¨äºè¯„ä¼°åŒ¹é…åº¦
                }
                for r in search_results
            ]
            
            if verbose:
                print(f"   æ£€ç´¢åˆ° {len(candidate_table)} ä¸ªå€™é€‰ç¿»è¯‘")
                if candidate_table:
                    print(f"\n   ã€è¯¦ç»†ã€‘æ£€ç´¢åˆ°çš„å€™é€‰ç¿»è¯‘:")
                    for i, cand in enumerate(candidate_table[:10], 1):
                        ctx_preview = cand.get('context', '')[:40] + '...' if cand.get('context') and len(cand.get('context', '')) > 40 else cand.get('context', 'æ— ')
                        print(f"   {i}. {cand['source']} â†’ {cand['target']}")
                        print(f"      ä¸Šä¸‹æ–‡: {ctx_preview}")
                    if len(candidate_table) > 10:
                        print(f"   ... è¿˜æœ‰ {len(candidate_table) - 10} ä¸ªå€™é€‰")
            
            # 2b) Evaluate Agent: è¯„ä¼°å’ŒéªŒè¯ç¿»è¯‘è´¨é‡
            if candidate_table:
                if verbose:
                    print(f"   âœ“ è¯„ä¼°æœ¯è¯­ç¿»è¯‘...")
                
                evaluate_agent = EvaluateAgent(locale=tgt_lang)
                evaluations = await evaluate_agent.execute({
                    "translations": candidate_table,
                    "source_text": text,
                    "source_lang": src_lang,
                    "target_lang": tgt_lang
                }, None)
                
                # åªä¿ç•™éªŒè¯é€šè¿‡çš„æœ¯è¯­
                if evaluations:
                    # é¦–å…ˆè¿‡æ»¤is_valid
                    valid_terms = [
                        {
                            'source': eval_result.term,
                            'target': eval_result.translation,
                            'confidence': eval_result.confidence
                        }
                        for eval_result in evaluations
                        if eval_result.is_valid
                    ]
                    if verbose:
                        print(f"   è¯„ä¼°åä¿ç•™ {len(valid_terms)} ä¸ªæœ‰æ•ˆæœ¯è¯­")
                        if valid_terms:
                            print(f"\n   ã€è¯¦ç»†ã€‘éªŒè¯åçš„æœ¯è¯­è¡¨:")
                            for i, term in enumerate(valid_terms[:10], 1):
                                print(f"   {i}. {term['source']} â†’ {term['target']} (ç½®ä¿¡åº¦: {term['confidence']:.2f})")
                            if len(valid_terms) > 10:
                                print(f"   ... è¿˜æœ‰ {len(valid_terms) - 10} ä¸ªæœ¯è¯­")
                    
                    
                    
                    # è½¬å›åˆ—è¡¨
                    term_table = valid_terms
                    
                    # ğŸšª é—¨æ§ï¼šåŸºäºç½®ä¿¡åº¦è¿‡æ»¤æœ¯è¯­
                    control_config = get_global_control_config()
                    if control_config and control_config.is_gating_enabled('terminology'):
                        threshold = control_config.terminology_threshold
                        before_count = len(term_table)
                        term_table = [
                            term for term in term_table
                            if term['confidence'] >= threshold
                        ]
                        filtered_count = before_count - len(term_table)
                        if verbose and filtered_count > 0:
                            print(f"   ğŸšª æœ¯è¯­é—¨æ§ï¼šè¿‡æ»¤äº† {filtered_count} ä¸ªä½ç½®ä¿¡åº¦æœ¯è¯­ï¼ˆé˜ˆå€¼: {threshold}ï¼‰")
                     
                    if verbose:
                        print(f"   è¿‡æ»¤åä¿ç•™ {len(term_table)} ä¸ªæœ‰æ•ˆæœ¯è¯­")
                        if term_table:
                            print(f"\n   ã€è¯¦ç»†ã€‘è¿‡æ»¤åçš„æœ¯è¯­è¡¨:")
                            for i, term in enumerate(term_table[:10], 1):
                                print(f"   {i}. {term['source']} â†’ {term['target']} (ç½®ä¿¡åº¦: {term['confidence']:.2f})")
                            if len(term_table) > 10:
                                print(f"   ... è¿˜æœ‰ {len(term_table) - 10} ä¸ªæœ¯è¯­")
                else:
                    term_table = candidate_table  # å¦‚æœè¯„ä¼°å¤±è´¥ï¼Œä¿ç•™å€™é€‰è¡¨
        
        # 3) Translation Agent: åŸºäºéªŒè¯æœ¯è¯­è¡¨ç”Ÿæˆåˆå§‹ç¿»è¯‘
        if verbose:
            print(f"   ğŸ¤– LLMç¿»è¯‘...")
        
        # æ£€æŸ¥æ˜¯å¦ä¸ºæœ¯è¯­å±‚å¯ç”¨å€™é€‰é€‰æ‹©
        generate_candidates = False
        num_candidates = 3
        if selection_config:
            generate_candidates = selection_config.is_selection_enabled('terminology')
            num_candidates = selection_config.get_num_candidates('terminology')
        
        translation_agent = TranslationAgent(
            locale=tgt_lang,
            generate_candidates=generate_candidates,
            num_candidates=num_candidates
        )
        translation_result = await translation_agent.execute({
            "source_text": text,
            "term_table": term_table,
            "source_lang": src_lang,
            "target_lang": tgt_lang
        }, None)
        
        # å¦‚æœç”Ÿæˆäº†å¤šä¸ªå€™é€‰ï¼Œä½¿ç”¨LLMé€‰æ‹©å™¨é€‰æ‹©æœ€ä½³
        if generate_candidates and translation_result.candidates and len(translation_result.candidates) > 1:
            if verbose:
                print(f"   ğŸ¯ LLMé€‰æ‹©å™¨ï¼šä»{len(translation_result.candidates)}ä¸ªå€™é€‰ä¸­é€‰æ‹©æœ€ä½³...")
            
            from ..agents.selector import LLMSelectorAgent
            selector = LLMSelectorAgent(locale=tgt_lang)
            
            # å‡†å¤‡ä¸Šä¸‹æ–‡ï¼ˆæœ¯è¯­è¡¨ä¿¡æ¯ï¼‰
            context = None
            if term_table:
                context_lines = ["æœ¯è¯­è¡¨:"]
                for term in term_table[:10]:  # æœ€å¤šæ˜¾ç¤º10ä¸ªæœ¯è¯­
                    context_lines.append(f"  {term.get('source', '')} â†’ {term.get('target', '')}")
                context = "\n".join(context_lines)
            
            selector_result = await selector.execute({
                'source_text': text,
                'candidates': translation_result.candidates,
                'context': context,
                'layer_type': 'terminology'
            }, None)
            
            # æ›´æ–°ç¿»è¯‘ç»“æœ
            translation_result.translated_text = selector_result.best_candidate
            translation_result.confidence = selector_result.confidence
            
            if verbose:
                print(f"   âœ“ é€‰æ‹©ç»“æœ: å€™é€‰#{selector_result.best_candidate_index + 1}, ç½®ä¿¡åº¦: {selector_result.confidence:.2f}")
                print(f"   ç†ç”±: {selector_result.reasoning[:100]}...")
        
        if verbose:
            print(f"\n   ã€è¯¦ç»†ã€‘ç¿»è¯‘ç»“æœ:")
            print(f"   æºæ–‡: {text}")
            print(f"   è¯‘æ–‡: {translation_result.translated_text}")
            print(f"   ç½®ä¿¡åº¦: {translation_result.confidence:.2f}\n")

        return {
            "extractedTerms": [term.__dict__ if hasattr(term, '__dict__') else term for term in extracted_terms],
            "termTable": term_table,
            "translatedText": translation_result.translated_text,
            "confidence": translation_result.confidence,
            "output": translation_result.translated_text,
            "source_text": text,  # ä¿å­˜æºæ–‡æœ¬ä¾›åç»­ä½¿ç”¨
            "candidates": translation_result.candidates if hasattr(translation_result, 'candidates') else None,  # å€™é€‰ç¿»è¯‘åˆ—è¡¨
            "terms_found": len(term_table)  # ç”¨äºç»Ÿè®¡æ˜¾ç¤º
        }
    
    except Exception as e:
        if verbose:
            print(f"   âš ï¸  æœ¯è¯­å±‚ç¿»è¯‘å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
        
        return {
            "output": text,
            "termTable": [],
            "terms_found": 0,
            "error": str(e)
        }
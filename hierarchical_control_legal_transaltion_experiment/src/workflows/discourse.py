"""
ç¯‡ç« ä¸€è‡´æ€§å·¥ä½œæµ - ä¸‰æ­¥ç¯‡ç« åˆ†æ-ç»¼åˆè¿‡ç¨‹
1. Query Agent: ä½¿ç”¨æ··åˆæ£€ç´¢è¯†åˆ«ç›¸å…³ç¿»è¯‘è®°å¿†
2. Evaluate Agent: åˆ†æå½“å‰ç¿»è¯‘ä¸å‚è€ƒçš„å·®å¼‚ï¼ˆç”¨è¯ã€å¥æ³•ã€é£æ ¼ï¼‰
3. Translation Agent: åŸºäºå·®å¼‚åˆ†æç»“æœè°ƒæ•´ç¿»è¯‘
"""
from typing import Dict, Any, Optional, TYPE_CHECKING
from ..agents.discourse.discourse_query import DiscourseQueryAgent
from ..agents.discourse.discourse_evaluate import DiscourseEvaluateAgent
from ..agents.discourse.discourse_translation import DiscourseTranslationAgent
from ..agents.utils import get_global_control_config

if TYPE_CHECKING:
    from ..agents.utils import TranslationControlConfig


async def run_discourse_workflow(
    source_text: str,
    current_translation: str,
    src_lang: str,
    tgt_lang: str,
    trace: Optional[Dict[str, Any]] = None,
    use_tm: bool = True,
    verbose: bool = False,
    selection_config: Optional['TranslationControlConfig'] = None
) -> Dict[str, Any]:
    """è¿è¡Œç¯‡ç« å·¥ä½œæµï¼šä¸‰æ­¥ç¯‡ç« åˆ†æ-ç»¼åˆè¿‡ç¨‹
    
    Args:
        source_text: æºæ–‡æœ¬
        current_translation: å½“å‰ç¿»è¯‘ï¼ˆæ¥è‡ªå‰ä¸€è½®ï¼‰
        src_lang: æºè¯­è¨€
        tgt_lang: ç›®æ ‡è¯­è¨€
        trace: å‰é¢è½®æ¬¡çš„traceä¿¡æ¯ï¼ˆå¯é€‰ï¼‰
        use_tm: æ˜¯å¦ä½¿ç”¨ç¿»è¯‘è®°å¿†ï¼ˆé»˜è®¤Trueï¼‰
        verbose: æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
    
    Returns:
        åŒ…å«æœ€ç»ˆç¿»è¯‘å’Œç¯‡ç« åˆ†æç»“æœçš„å­—å…¸
    """
    try:
        # åˆå§‹åŒ–TMç›¸å…³å˜é‡
        tm_results = []
        evaluation = None
        top_references = []
        
        # 1) Query Agent: ä½¿ç”¨æ··åˆæ£€ç´¢è¯†åˆ«ç›¸å…³ç¿»è¯‘è®°å¿†ï¼ˆå¯é€‰ï¼‰
        if use_tm:
            if verbose:
                print(f"   ğŸ” æ£€ç´¢ç¿»è¯‘è®°å¿†...")
            
            query_agent = DiscourseQueryAgent(locale=tgt_lang)
            tm_results = await query_agent.execute({
                "text": source_text,  # ä½¿ç”¨æºæ–‡æœ¬æ£€ç´¢
                "source_lang": src_lang,
                "target_lang": tgt_lang,
                "top_k": 5
            }, None)
            
            if verbose:
                if tm_results:
                    print(f"   æ£€ç´¢åˆ° {len(tm_results)} ä¸ªç›¸å…³ç¿»è¯‘è®°å¿†")
                    print(f"\n   ã€è¯¦ç»†ã€‘å‰5ä¸ªæœ€ä½³åŒ¹é…:")
                    for i, tm in enumerate(tm_results[:5], 1):
                        print(f"   {i}. ç›¸ä¼¼åº¦: {tm.similarity_score:.2f}")
                        print(f"      æº: {tm.source_text[:50]}...")
                        print(f"      è¯‘: {tm.target_text[:50]}...")
                else:
                    print(f"   æœªæ‰¾åˆ°ç›¸å…³ç¿»è¯‘è®°å¿†")
        else:
            if verbose:
                print(f"   âš ï¸ ç¿»è¯‘è®°å¿†å·²ç¦ç”¨ï¼Œè·³è¿‡TMæ£€ç´¢")
        
        # 2) Evaluate Agent: åˆ†æå½“å‰ç¿»è¯‘ä¸å‰3ä¸ªå‚è€ƒçš„å·®å¼‚
        if use_tm and tm_results:
            # é€‰æ‹©å‰3ä¸ªæœ€ä½³åŒ¹é…ä½œä¸ºå‚è€ƒ
            top_references = [
                {
                    'source_text': tm.source_text,
                    'target_text': tm.target_text,
                    'similarity_score': tm.similarity_score,
                    'context': getattr(tm, 'context', ''),
                    'legal_domain': getattr(tm, 'legal_domain', '')
                }
                for tm in tm_results[:3]
            ]
            
            if verbose:
                print(f"   âœ“ è¯„ä¼°ä¸å‚è€ƒè¯‘æ–‡çš„å·®å¼‚...")
                # æ˜¾ç¤ºä½¿ç”¨çš„TMå‚è€ƒ
                print(f"\n   ã€è¯¦ç»†ã€‘ä½¿ç”¨çš„TMå‚è€ƒ ({len(top_references)} æ¡):")
                for i, ref in enumerate(top_references[:3], 1):
                    similarity = ref.get('similarity_score', 0.0)  # ä½¿ç”¨æ­£ç¡®çš„å­—æ®µå
                    print(f"   {i}. ç›¸ä¼¼åº¦: {similarity:.2f}")
                    print(f"      æº: {ref.get('source_text', '')[:60]}...")  # ä½¿ç”¨æ­£ç¡®çš„å­—æ®µå
                    print(f"      è¯‘: {ref.get('target_text', '')[:60]}...")  # ä½¿ç”¨æ­£ç¡®çš„å­—æ®µå
                if len(top_references) > 3:
                    print(f"   ... è¿˜æœ‰ {len(top_references) - 3} æ¡å‚è€ƒ")
            
            evaluate_agent = DiscourseEvaluateAgent(locale=tgt_lang)
            evaluation = await evaluate_agent.execute({
                "source_text": source_text,
                "text": current_translation,
                "references": top_references,
                "target_lang": tgt_lang
            }, None)
            
            if verbose and evaluation:
                print(f"\n   ã€è¯¦ç»†ã€‘ç¯‡ç« è¯„ä¼°ç»“æœ:")
                print(f"   - æ€»ä½“è¯„ä¼°åˆ†æ•°: {evaluation.overall_score:.2f}")
                
                # æ˜¾ç¤ºå„ç»´åº¦è¯„åˆ†
                if hasattr(evaluation, 'coherence_score'):
                    print(f"   - è¿è´¯æ€§: {evaluation.coherence_score:.2f}")
                if hasattr(evaluation, 'style_consistency'):
                    print(f"   - é£æ ¼ä¸€è‡´æ€§: {evaluation.style_consistency:.2f}")
                if hasattr(evaluation, 'terminology_consistency'):
                    print(f"   - æœ¯è¯­ä¸€è‡´æ€§: {evaluation.terminology_consistency:.2f}")
                
                # æ˜¾ç¤ºæ”¹è¿›å»ºè®®
                if hasattr(evaluation, 'suggestions') and evaluation.suggestions:
                    print(f"\n   ã€è¯¦ç»†ã€‘æ”¹è¿›å»ºè®® ({len(evaluation.suggestions)} æ¡):")
                    for i, suggestion in enumerate(evaluation.suggestions[:3], 1):
                        print(f"   {i}. {suggestion}")
                    if len(evaluation.suggestions) > 3:
                        print(f"   ... è¿˜æœ‰ {len(evaluation.suggestions) - 3} æ¡å»ºè®®")
        
        # ğŸšª é—¨æ§ï¼šæ£€æŸ¥æ˜¯å¦éœ€è¦åº”ç”¨ç¯‡ç« ä¿®æ”¹ï¼ˆåŸºäºè¯„ä¼°åˆ†æ•°æˆ–TMè´¨é‡ï¼‰
        control_config = get_global_control_config()
        if control_config and control_config.is_gating_enabled('discourse'):
            # å¦‚æœè¯„ä¼°åˆ†æ•°é«˜ï¼Œæˆ–è€…æ²¡æœ‰æœ‰æ•ˆçš„TMå‚è€ƒï¼Œå¯èƒ½ä¸éœ€è¦ä¿®æ”¹
            should_modify = True
            
            # æ£€æŸ¥è¯„ä¼°åˆ†æ•°
            if evaluation and hasattr(evaluation, 'overall_score'):
                if not control_config.should_apply_discourse_modification(evaluation.overall_score):
                    should_modify = False
                    if verbose:
                        threshold = control_config.discourse_threshold
                        print(f"   ğŸšª ç¯‡ç« é—¨æ§ï¼šè¯„ä¼°åˆ†æ•° {evaluation.overall_score:.2f} â‰¥ {threshold}ï¼Œç¿»è¯‘è´¨é‡è‰¯å¥½ï¼Œä¸ä¿®æ”¹")
            
            # æ£€æŸ¥æ˜¯å¦æœ‰æœ‰æ•ˆçš„TMå‚è€ƒ
            if should_modify and not top_references:
                should_modify = False
                if verbose:
                    print(f"   ğŸšª ç¯‡ç« é—¨æ§ï¼šæ— æœ‰æ•ˆTMå‚è€ƒï¼Œä¸ä¿®æ”¹")
            
            if not should_modify:
                return {
                    "tm_results": [tm.__dict__ if hasattr(tm, '__dict__') else tm for tm in tm_results] if tm_results else [],
                    "evaluation": evaluation.__dict__ if evaluation and hasattr(evaluation, '__dict__') else None,
                    "finalText": current_translation,  # ä¿æŒåŸæ–‡ä¸å˜
                    "appliedPatches": [],
                    "trace": trace or {},
                    "confidence": 1.0,
                    "output": current_translation,
                    "candidates": None,
                    "gated": True  # æ ‡è®°ä¸ºè¢«é—¨æ§ä¿æŠ¤
                }
        
        # 3) Translation Agent: åŸºäºå·®å¼‚åˆ†æç»“æœè°ƒæ•´ç¿»è¯‘
        if verbose:
            print(f"\n   ğŸ¤– ç¯‡ç« å±‚ç¿»è¯‘æ•´åˆ...")
            if evaluation:
                score = getattr(evaluation, 'overall_score', 0)
                control_config = get_global_control_config()
                # ä½¿ç”¨å…¨å±€é…ç½®æˆ–é»˜è®¤é˜ˆå€¼
                default_threshold = 0.8
                threshold = control_config.discourse_threshold if control_config else default_threshold
                
                # æ ¹æ®é—¨æ§çŠ¶æ€æ˜¾ç¤ºä¸åŒä¿¡æ¯
                gating_enabled = control_config and control_config.is_gating_enabled('discourse')
                if gating_enabled:
                    # é—¨æ§å¯ç”¨æ—¶ï¼Œèƒ½æ‰§è¡Œåˆ°è¿™é‡Œè¯´æ˜åˆ†æ•°ä½äºé˜ˆå€¼
                    print(f"   - è¯„ä¼°åˆ†æ•°: {score:.2f} < é˜ˆå€¼ {threshold}ï¼ˆéœ€è¦æ”¹è¿›ï¼‰")
                else:
                    # é—¨æ§æœªå¯ç”¨ï¼Œåªæ˜¾ç¤ºåˆ†æ•°
                    print(f"   - è¯„ä¼°åˆ†æ•°: {score:.2f}ï¼ˆé—¨æ§æœªå¯ç”¨ï¼Œæ‰§è¡Œç¿»è¯‘æ•´åˆï¼‰")
            
            if top_references:
                print(f"   - å‚è€ƒ {len(top_references)} ä¸ªTMè®°å¿†è¿›è¡Œé£æ ¼æ•´åˆ")
                avg_sim = sum(ref.get('similarity_score', 0) for ref in top_references) / len(top_references)  # ä½¿ç”¨æ­£ç¡®çš„å­—æ®µå
                print(f"   - å¹³å‡ç›¸ä¼¼åº¦: {avg_sim:.2f}")
        
        # æ£€æŸ¥æ˜¯å¦ä¸ºç¯‡ç« å±‚å¯ç”¨å€™é€‰é€‰æ‹©
        generate_candidates = False
        num_candidates = 3
        if selection_config:
            generate_candidates = selection_config.is_selection_enabled('discourse')
            num_candidates = selection_config.get_num_candidates('discourse')
        
        translation_agent = DiscourseTranslationAgent(
            locale=tgt_lang,
            generate_candidates=generate_candidates,
            num_candidates=num_candidates
        )
        
        # å‡†å¤‡é€‰ä¸­çš„å‚è€ƒï¼ˆä½¿ç”¨åˆ†æè¿‡çš„å‰3ä¸ªï¼‰
        selected_references = []
        if tm_results:
            # ğŸšª é—¨æ§ï¼šåŸºäºç›¸ä¼¼åº¦è¿‡æ»¤TMå‚è€ƒ
            control_config = get_global_control_config()
            filtered_tms = tm_results[:3]  # é»˜è®¤ä½¿ç”¨å‰3ä¸ª
            
            if control_config and control_config.is_gating_enabled('discourse'):
                tm_threshold = control_config.tm_similarity_threshold
                before_count = len(tm_results[:3])
                filtered_tms = [
                    tm for tm in tm_results[:3]
                    if tm.similarity_score >= tm_threshold
                ]
                filtered_count = before_count - len(filtered_tms)
                if verbose and filtered_count > 0:
                    print(f"   ğŸšª TMé—¨æ§ï¼šè¿‡æ»¤äº† {filtered_count} ä¸ªä½ç›¸ä¼¼åº¦TMï¼ˆé˜ˆå€¼: {tm_threshold}ï¼‰")
            
            for tm in filtered_tms:
                selected_references.append({
                    'reference': f"{tm.source_text} â†’ {tm.target_text}",
                    'weight': tm.similarity_score,
                    'source': tm.source_text,
                    'target': tm.target_text
                })
            
            if verbose and selected_references:
                print(f"   ä½¿ç”¨ {len(selected_references)} ä¸ªç­›é€‰åçš„TMå‚è€ƒ")
        
        translation_result = await translation_agent.execute({
            "source_text": source_text,
            "current_translation": current_translation,
            "selected_references": selected_references,
            "evaluation": evaluation,
            "syntactic_suggestions": [],  # å¯ä»ä¸Šä¸€è½®è·å–
            "source_lang": src_lang,
            "target_lang": tgt_lang
        }, None)
        
        if verbose:
            if hasattr(translation_result, 'refined_translation') and translation_result.refined_translation:
                print(f"\n   ã€è¯¦ç»†ã€‘ç¯‡ç« å±‚ç¿»è¯‘ç»“æœ:")
                print(f"   - è¾“å…¥: {current_translation[:80]}...")
                print(f"   - è¾“å‡º: {translation_result.refined_translation[:80]}...")
                if current_translation == translation_result.refined_translation:
                    print(f"   - çŠ¶æ€: æœªä¿®æ”¹ï¼ˆä¿æŒåŸç¿»è¯‘ï¼‰")
                else:
                    print(f"   - çŠ¶æ€: å·²ä¼˜åŒ–")
        
        # å¦‚æœç”Ÿæˆäº†å¤šä¸ªå€™é€‰ï¼Œä½¿ç”¨LLMé€‰æ‹©å™¨é€‰æ‹©æœ€ä½³
        if generate_candidates and translation_result.candidates and len(translation_result.candidates) > 1:
            if verbose:
                print(f"   ğŸ¯ LLMé€‰æ‹©å™¨ï¼šä»{len(translation_result.candidates)}ä¸ªå€™é€‰ä¸­é€‰æ‹©æœ€ä½³...")
            
            from ..agents.selector import LLMSelectorAgent
            selector = LLMSelectorAgent(locale=tgt_lang)
            
            # å‡†å¤‡ä¸Šä¸‹æ–‡ï¼ˆTMå‚è€ƒå’Œè¯„ä¼°ä¿¡æ¯ï¼‰
            context = None
            if selected_references or evaluation:
                context_lines = []
                if selected_references:
                    context_lines.append(f"å‚è€ƒè¯‘æ–‡: {len(selected_references)}æ¡")
                    for ref in selected_references[:2]:
                        context_lines.append(f"  - {ref.get('target', '')[:50]}...")
                if evaluation:
                    context_lines.append(f"è¯„ä¼°: {getattr(evaluation, 'overall_score', 'N/A')}")
                context = "\n".join(context_lines)
            
            selector_result = await selector.execute({
                'source_text': source_text,
                'candidates': translation_result.candidates,
                'context': context,
                'layer_type': 'discourse'
            }, None)
            
            # æ›´æ–°ç¿»è¯‘ç»“æœ
            translation_result.final_text = selector_result.best_candidate
            translation_result.confidence = selector_result.confidence
            
            if verbose:
                print(f"   âœ“ é€‰æ‹©ç»“æœ: å€™é€‰#{selector_result.best_candidate_index + 1}, ç½®ä¿¡åº¦: {selector_result.confidence:.2f}")
                print(f"   ç†ç”±: {selector_result.reasoning[:100]}...")
        
        if verbose:
            print(f"\n   ã€è¯¦ç»†ã€‘ç¯‡ç« æ•´åˆ:")
            print(f"   æ•´åˆå‰: {current_translation}")
            print(f"   æ•´åˆå: {translation_result.final_text}")

        return {
            "references": [
                {
                    'source_text': tm.source_text,
                    'target_text': tm.target_text,
                    'similarity_score': tm.similarity_score
                } for tm in tm_results[:3]
            ] if tm_results else [],
            "evaluation": evaluation.__dict__ if evaluation and hasattr(evaluation, '__dict__') else None,
            "finalText": translation_result.final_text,
            "integratedReferences": translation_result.integrated_references,
            "memoryUpdates": translation_result.memory_updates,
            # å…¼å®¹æ—§å­—æ®µå
            "tm_used": len(tm_results) > 0 if tm_results else False,
            "tm_matches": len(tm_results) if tm_results else 0,
            "tm_applied": len(translation_result.integrated_references) if translation_result.integrated_references else 0,
            "coherence": getattr(evaluation, 'overall_score', 0.0) if evaluation else 0.0,
            "discourse_score": translation_result.confidence if hasattr(translation_result, 'confidence') else 0.0,
            "confidence": getattr(evaluation, 'overall_score', 1.0) if evaluation else 1.0,
            "output": translation_result.final_text,
            "candidates": translation_result.candidates if hasattr(translation_result, 'candidates') else None  # å€™é€‰ç¿»è¯‘åˆ—è¡¨
        }
    
    except Exception as e:
        if verbose:
            print(f"   âš ï¸  ç¯‡ç« å±‚ç¿»è¯‘å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
        
        return {
            "output": current_translation,
            "error": str(e)
        }
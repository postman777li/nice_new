#!/usr/bin/env python3
"""
é¢„ä¸‹è½½è¯„ä¼°æ‰€éœ€çš„æ‰€æœ‰æ¨¡å‹
é¿å…åœ¨è¯„ä¼°æ—¶ä¸‹è½½ï¼ŒèŠ‚çœæ—¶é—´
"""
import os
import sys
import shutil
from pathlib import Path

sys.path.insert(0, str(Path(__file__).parent))


def setup_hf_mirror(use_mirror=True):
    """è®¾ç½® HF é•œåƒ"""
    if use_mirror:
        os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'
        print("âœ“ å·²å¯ç”¨ Hugging Face é•œåƒåŠ é€Ÿ: https://hf-mirror.com")
    else:
        if 'HF_ENDPOINT' in os.environ:
            del os.environ['HF_ENDPOINT']
        print("âœ“ ä½¿ç”¨å®˜æ–¹ Hugging Face Hub")


def clean_model_cache(model_name):
    """æ¸…ç†æŒ‡å®šæ¨¡å‹çš„ç¼“å­˜"""
    cache_dir = Path.home() / ".cache" / "huggingface" / "hub"
    
    # è½¬æ¢æ¨¡å‹åç§°ä¸ºç¼“å­˜ç›®å½•æ ¼å¼
    # ä¾‹å¦‚: xlm-roberta-large -> models--xlm-roberta-large
    # Unbabel/wmt22-comet-da -> models--Unbabel--wmt22-comet-da
    cache_name = "models--" + model_name.replace("/", "--")
    cache_path = cache_dir / cache_name
    
    if cache_path.exists():
        try:
            print(f"   æ¸…ç†æ—§ç¼“å­˜: {cache_path}")
            shutil.rmtree(cache_path)
            print(f"   âœ… ç¼“å­˜å·²æ¸…ç†")
            return True
        except Exception as e:
            print(f"   âš ï¸  æ¸…ç†å¤±è´¥: {e}")
            return False
    else:
        print(f"   â„¹ï¸  æœªæ‰¾åˆ°ç¼“å­˜: {cache_name}")
        return True


def download_bertscore_model(clean_cache=False, use_mirror=True):
    """ä¸‹è½½ BERTScore æ¨¡å‹"""
    print("="*60)
    print("1. ä¸‹è½½ BERTScore æ¨¡å‹")
    print("="*60)
    
    model_type = "xlm-roberta-large"
    
    if clean_cache:
        print("æ¸…ç†æ—§ç¼“å­˜...")
        clean_model_cache(model_type)
    
    try:
        setup_hf_mirror(use_mirror)
        
        from transformers import AutoModel, AutoTokenizer
        import torch
        
        print(f"æ¨¡å‹: {model_type}")
        print(f"å¤§å°: ~1.4 GB")
        print("å¼€å§‹ä¸‹è½½...\n")
        
        # ä¸‹è½½tokenizerå’Œmodel
        print("   ä¸‹è½½ tokenizer...")
        tokenizer = AutoTokenizer.from_pretrained(model_type)
        print("   âœ… Tokenizer ä¸‹è½½å®Œæˆ")
        
        print("   ä¸‹è½½ model...")
        model = AutoModel.from_pretrained(model_type)
        print("   âœ… Model ä¸‹è½½å®Œæˆ")
        
        # ä½¿ç”¨ BERTScorer ç¡®ä¿å®Œæ•´ä¸‹è½½
        print("\n   åˆå§‹åŒ– BERTScorer...")
        from bert_score import BERTScorer
        
        device = 'cuda' if torch.cuda.is_available() else 'cpu'
        scorer = BERTScorer(
            model_type=model_type,
            lang="zh",
            device=device,
            rescale_with_baseline=False
        )
        
        print(f"âœ… BERTScore æ¨¡å‹ä¸‹è½½å®Œæˆ")
        print(f"   æ¨¡å‹: {scorer._model.config._name_or_path}")
        print(f"   è®¾å¤‡: {device}")
        
        # æµ‹è¯•ä¸€ä¸‹
        test_pred = ["è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•"]
        test_ref = ["è¿™æ˜¯æµ‹è¯•"]
        P, R, F1 = scorer.score(test_pred, test_ref)
        print(f"   æµ‹è¯•åˆ†æ•°: F1={F1.mean().item():.4f}")
        
        return True
    except Exception as e:
        print(f"âŒ BERTScore æ¨¡å‹ä¸‹è½½å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def download_comet_model(clean_cache=False, use_mirror=True):
    """ä¸‹è½½ COMET æ¨¡å‹"""
    print("\n" + "="*60)
    print("2. ä¸‹è½½ COMET æ¨¡å‹")
    print("="*60)
    
    model_name = "Unbabel/wmt22-comet-da"
    
    if clean_cache:
        print("æ¸…ç†æ—§ç¼“å­˜...")
        clean_model_cache(model_name)
    
    try:
        setup_hf_mirror(use_mirror)
        
        from comet import download_model, load_from_checkpoint
        
        print(f"æ¨¡å‹: {model_name}")
        print(f"å¤§å°: ~2.3 GB")
        print("å¼€å§‹ä¸‹è½½...\n")
        
        model_path = download_model(model_name)
        print(f"âœ… COMET æ¨¡å‹ä¸‹è½½å®Œæˆ")
        print(f"   æ¨¡å‹è·¯å¾„: {model_path}")
        
        # åŠ è½½æ¨¡å‹æµ‹è¯•
        print("   åŠ è½½æ¨¡å‹è¿›è¡Œæµ‹è¯•...")
        model = load_from_checkpoint(model_path)
        
        # æµ‹è¯•ä¸€ä¸‹
        data = [{
            "src": "åˆåŒåŒæ–¹åº”å½“éµå®ˆæœ¬åè®®çš„æ‰€æœ‰æ¡æ¬¾ã€‚",
            "mt": "The parties shall comply with all terms.",
            "ref": "The parties must comply with all terms."
        }]
        result = model.predict(data, batch_size=1, gpus=0)
        print(f"   æµ‹è¯•åˆ†æ•°: {result['scores'][0]:.4f}")
        
        return True
    except Exception as e:
        print(f"âŒ COMET æ¨¡å‹ä¸‹è½½å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def check_disk_space():
    """æ£€æŸ¥ç£ç›˜ç©ºé—´"""
    print("="*60)
    print("ç£ç›˜ç©ºé—´æ£€æŸ¥")
    print("="*60)
    
    import shutil
    
    cache_dir = Path.home() / ".cache" / "huggingface"
    cache_dir.mkdir(parents=True, exist_ok=True)
    
    total, used, free = shutil.disk_usage(cache_dir)
    
    print(f"ç¼“å­˜ç›®å½•: {cache_dir}")
    print(f"æ€»ç©ºé—´: {total / (1024**3):.1f} GB")
    print(f"å·²ä½¿ç”¨: {used / (1024**3):.1f} GB")
    print(f"å¯ç”¨ç©ºé—´: {free / (1024**3):.1f} GB")
    
    required_gb = 4  # BERTScore (1.4GB) + COMET (2.3GB) + ä½™é‡
    if free / (1024**3) < required_gb:
        print(f"\nâš ï¸  è­¦å‘Š: ç£ç›˜ç©ºé—´ä¸è¶³ {required_gb} GB")
        print(f"   å»ºè®®æ¸…ç†ç¼“å­˜æˆ–å¢åŠ ç£ç›˜ç©ºé—´")
        return False
    else:
        print(f"\nâœ… ç£ç›˜ç©ºé—´å……è¶³ (éœ€è¦ ~{required_gb} GB)")
        return True


def show_cache_info():
    """æ˜¾ç¤ºç¼“å­˜ä¿¡æ¯"""
    print("\n" + "="*60)
    print("æ¨¡å‹ç¼“å­˜ä¿¡æ¯")
    print("="*60)
    
    cache_dir = Path.home() / ".cache" / "huggingface"
    
    if cache_dir.exists():
        # ç»Ÿè®¡ç¼“å­˜å¤§å°
        total_size = 0
        file_count = 0
        for path in cache_dir.rglob("*"):
            if path.is_file():
                total_size += path.stat().st_size
                file_count += 1
        
        print(f"ç¼“å­˜ç›®å½•: {cache_dir}")
        print(f"æ–‡ä»¶æ•°é‡: {file_count}")
        print(f"æ€»å¤§å°: {total_size / (1024**3):.2f} GB")
        
        # åˆ—å‡ºä¸»è¦æ¨¡å‹
        hub_dir = cache_dir / "hub"
        if hub_dir.exists():
            print(f"\nå·²ç¼“å­˜çš„æ¨¡å‹ (å‰20ä¸ª):")
            model_dirs = [d for d in hub_dir.iterdir() if d.is_dir() and d.name.startswith('models--')]
            for model_dir in sorted(model_dirs)[:20]:
                model_name = model_dir.name.replace('models--', '').replace('--', '/')
                size = sum(f.stat().st_size for f in model_dir.rglob("*") if f.is_file())
                print(f"   - {model_name}: {size / (1024**3):.2f} GB")
    else:
        print(f"ç¼“å­˜ç›®å½•ä¸å­˜åœ¨: {cache_dir}")
        print("å°†åœ¨ä¸‹è½½æ¨¡å‹æ—¶è‡ªåŠ¨åˆ›å»º")


def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='é¢„ä¸‹è½½è¯„ä¼°æ‰€éœ€çš„æ¨¡å‹')
    parser.add_argument('--clean', action='store_true', help='æ¸…ç†æ—§ç¼“å­˜åé‡æ–°ä¸‹è½½')
    parser.add_argument('--no-mirror', action='store_true', help='ä¸ä½¿ç”¨ HF é•œåƒ')
    parser.add_argument('--bert-only', action='store_true', help='ä»…ä¸‹è½½ BERTScore æ¨¡å‹')
    parser.add_argument('--comet-only', action='store_true', help='ä»…ä¸‹è½½ COMET æ¨¡å‹')
    args = parser.parse_args()
    
    print("\n" + "="*60)
    print(" "*15 + "æ¨¡å‹é¢„ä¸‹è½½å·¥å…·")
    print("="*60 + "\n")
    
    use_mirror = not args.no_mirror
    
    if args.clean:
        print("âš ï¸  æ¸…ç†æ¨¡å¼: å°†åˆ é™¤æ—§ç¼“å­˜åé‡æ–°ä¸‹è½½\n")
    
    if not (args.bert_only or args.comet_only):
        print("æ­¤è„šæœ¬å°†ä¸‹è½½ä»¥ä¸‹æ¨¡å‹:")
        print("  1. xlm-roberta-large (BERTScore) - ~1.4 GB")
        print("  2. wmt22-comet-da (COMET) - ~2.3 GB")
        print("  æ€»è®¡: ~3.7 GB\n")
    
    # æ£€æŸ¥ç£ç›˜ç©ºé—´
    if not check_disk_space():
        print("\nâŒ ç£ç›˜ç©ºé—´ä¸è¶³ï¼Œè¯·æ¸…ç†åé‡è¯•")
        return
    
    print("\n" + "="*60)
    print("å¼€å§‹ä¸‹è½½æ¨¡å‹")
    print("="*60 + "\n")
    
    # ä¸‹è½½æ¨¡å‹
    results = []
    
    if not args.comet_only:
        results.append(("BERTScore", download_bertscore_model(
            clean_cache=args.clean, 
            use_mirror=use_mirror
        )))
    
    if not args.bert_only:
        results.append(("COMET", download_comet_model(
            clean_cache=args.clean,
            use_mirror=use_mirror
        )))
    
    # æ˜¾ç¤ºç¼“å­˜ä¿¡æ¯
    show_cache_info()
    
    # æ€»ç»“
    print("\n" + "="*60)
    print("ä¸‹è½½æ€»ç»“")
    print("="*60)
    
    for name, success in results:
        status = "âœ… æˆåŠŸ" if success else "âŒ å¤±è´¥"
        print(f"{name:15s}: {status}")
    
    all_success = all(success for _, success in results)
    
    if all_success:
        print("\nğŸ‰ æ‰€æœ‰æ¨¡å‹ä¸‹è½½å®Œæˆï¼")
        print("\nç°åœ¨å¯ä»¥è¿è¡Œè¯„ä¼°è„šæœ¬ï¼Œæ— éœ€ç­‰å¾…ä¸‹è½½ï¼š")
        print("  python evaluate_results.py outputs/experiment_results.json --metrics bleu chrf bertscore comet")
    else:
        print("\nâš ï¸  éƒ¨åˆ†æ¨¡å‹ä¸‹è½½å¤±è´¥")
        print("\nå»ºè®®:")
        print("  1. æ£€æŸ¥ç½‘ç»œè¿æ¥")
        print("  2. å¦‚æœé•œåƒæœ‰é—®é¢˜ï¼Œå°è¯•ä¸ä½¿ç”¨é•œåƒ:")
        print("     python download_models.py --no-mirror --clean")
        print("  3. åˆ†åˆ«ä¸‹è½½å„ä¸ªæ¨¡å‹:")
        print("     python download_models.py --bert-only --clean")
        print("     python download_models.py --comet-only --clean")


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n\nâš ï¸  ä¸‹è½½å·²å–æ¶ˆ")
        sys.exit(1)
    except Exception as e:
        print(f"\nâŒ å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)

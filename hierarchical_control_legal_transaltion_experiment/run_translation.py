#!/usr/bin/env python3
"""
ç®€åŒ–çš„æœ¬åœ°ç¿»è¯‘å·¥å…·
ç›´æ¥è¿è¡Œç¿»è¯‘ï¼Œæ— éœ€APIæœåŠ¡å™¨
"""
import asyncio
import argparse
import json
import sys
from pathlib import Path
from typing import Dict, Any

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

# å¯¼å…¥é…ç½®
# é—¨æ§é˜ˆå€¼é…ç½®å·²ç§»é™¤ï¼Œç›´æ¥ä½¿ç”¨ç¡¬ç¼–ç é»˜è®¤å€¼

from src.workflows.terminology import run_terminology_workflow
from src.workflows.syntax import run_syntactic_workflow
from src.workflows.discourse import run_discourse_workflow
from src.agents.baseline_translation import BaselineTranslationAgent
from src.agents.quality_assessor import QualityAssessorAgent
from src.agents.utils import TranslationControlConfig, set_global_control_config


class SimpleTranslator:
    """ç®€åŒ–çš„ç¿»è¯‘å™¨"""
    
    def __init__(self, config: Dict[str, Any], verbose: bool = False):
        self.config = config
        self.verbose = verbose
        # æ”¯æŒæŒ‡å®šè¿è¡Œå“ªäº›è½®æ¬¡ï¼ˆç”¨äºæ¶ˆèå®éªŒï¼‰
        self.max_rounds = config.get('max_rounds', 3)  # 1, 2, æˆ– 3
        
        # åˆ›å»ºç»Ÿä¸€çš„ç¿»è¯‘æ§åˆ¶é…ç½®ï¼ˆæ•´åˆå€™é€‰é€‰æ‹©å’Œé—¨æ§ï¼‰
        # æ”¯æŒæ–°å‚æ•°åå’Œæ—§å‚æ•°åï¼ˆå‘åå…¼å®¹ï¼‰
        selection_layers = config.get('selection_layers') or config.get('comet_layers') or 'none'
        num_candidates = config.get('num_candidates') or config.get('comet_candidates', 3)
        gating_layers = config.get('gating_layers', 'none')
        
        control_config = TranslationControlConfig.from_args(
            selection_layers=selection_layers,
            num_candidates=num_candidates,
            gating_layers=gating_layers,
            term_threshold=config.get('term_gate_threshold', 0.8),
            syntax_threshold=config.get('syntax_gate_threshold', 0.8),
            discourse_threshold=config.get('discourse_gate_threshold', 0.8),
            tm_threshold=config.get('tm_gate_threshold', 0.7)
        )
        
        # è®¾ç½®ä¸ºå…¨å±€é…ç½®ï¼ˆä¾›workflowsä½¿ç”¨ï¼‰
        set_global_control_config(control_config)
        
        # ä¿ç•™selection_configå±æ€§ä»¥ä¿æŒå‘åå…¼å®¹
        self.selection_config = control_config
        
        if verbose:
            print(f"âœ“ ç¿»è¯‘æ§åˆ¶é…ç½®: {control_config}")
    
    async def translate(self, source: str, src_lang: str, tgt_lang: str) -> Dict[str, Any]:
        """æ‰§è¡Œç¿»è¯‘"""
        print(f"\n{'='*60}")
        print(f"ç¿»è¯‘ä»»åŠ¡")
        print(f"{'='*60}")
        print(f"æºè¯­è¨€: {src_lang}")
        print(f"ç›®æ ‡è¯­è¨€: {tgt_lang}")
        print(f"æºæ–‡æœ¬: {source}")
        print(f"{'='*60}\n")
        
        # ä½¿ç”¨é…ç½®
        hierarchical = self.config.get('hierarchical', True)
        use_termbase = self.config.get('useTermBase', True)
        use_tm = self.config.get('useTM', True)
        
        result = {
            'source': source,
            'src_lang': src_lang,
            'tgt_lang': tgt_lang,
            'config': self.config,
            'trace': {}
        }
        
        try:
            if hierarchical:
                # å±‚æ¬¡åŒ–å·¥ä½œæµï¼ˆæ ¹æ®max_roundsæ§åˆ¶è¿è¡Œå“ªäº›è½®æ¬¡ï¼‰
                # è½®æ¬¡1: æœ¯è¯­å±‚ç¿»è¯‘
                print("ğŸ” è½®æ¬¡1: æœ¯è¯­å±‚ç¿»è¯‘...")
                r1_result = await self._run_terminology_round(
                    source, src_lang, tgt_lang, use_termbase
                )
                result['trace']['r1'] = r1_result
                result['r1_output'] = r1_result.get('output', source)
                print(f"   ç»“æœ: {result['r1_output']}\n")
                result['final'] = result['r1_output']  # é»˜è®¤ç¬¬ä¸€è½®ç»“æœ
                
                # è½®æ¬¡2: å¥æ³•å±‚ç¿»è¯‘ï¼ˆå¦‚æœå¯ç”¨ï¼‰
                if self.max_rounds >= 2:
                    print("ğŸ” è½®æ¬¡2: å¥æ³•å±‚ç¿»è¯‘...")
                    r1_target = result['r1_output']
                    r2_result = await self._run_syntax_round(
                        source, r1_target, src_lang, tgt_lang
                    )
                    result['trace']['r2'] = r2_result
                    result['r2_output'] = r2_result.get('output', result['r1_output'])
                    print(f"   ç»“æœ: {result['r2_output']}\n")
                    
                    # è°ƒè¯•ï¼šæ£€æŸ¥r2æ˜¯å¦æ”¹è¿›äº†ç¿»è¯‘
                    if result['r1_output'] == result['r2_output']:
                        print(f"   âš ï¸  å¥æ³•å±‚æœªæ”¹è¿›ç¿»è¯‘ï¼ˆè¾“å‡ºä¸è¾“å…¥ç›¸åŒï¼‰")
                    else:
                        print(f"   âœ“ å¥æ³•å±‚æ”¹è¿›äº†ç¿»è¯‘")
                    
                    result['final'] = result['r2_output']  # æ›´æ–°ä¸ºç¬¬äºŒè½®ç»“æœ
                
                # è½®æ¬¡3: ç¯‡ç« å±‚æ•´åˆï¼ˆå¦‚æœå¯ç”¨ï¼‰
                if self.max_rounds >= 3:
                    print("ğŸ” è½®æ¬¡3: ç¯‡ç« å±‚æ•´åˆ...")
                    r2_or_r1_output = result['final']  # ä¿å­˜ä¸Šä¸€è½®çš„è¾“å‡º
                    r3_result = await self._run_discourse_round(
                        result['final'], src_lang, tgt_lang, result['trace'], use_tm=use_tm
                    )
                    result['trace']['r3'] = r3_result
                    result['final'] = r3_result.get('output', result['final'])
                    print(f"   ç»“æœ: {result['final']}\n")
                    
                    # è°ƒè¯•ï¼šæ£€æŸ¥r3æ˜¯å¦æ”¹è¿›äº†ç¿»è¯‘
                    if r2_or_r1_output == result['final']:
                        print(f"   âš ï¸  ç¯‡ç« å±‚æœªæ”¹è¿›ç¿»è¯‘ï¼ˆè¾“å‡ºä¸è¾“å…¥ç›¸åŒï¼‰")
                    else:
                        print(f"   âœ“ ç¯‡ç« å±‚æ”¹è¿›äº†ç¿»è¯‘")
            else:
                # å•è½®ç›´æ¥ç¿»è¯‘ï¼ˆçº¯LLMåŸºçº¿ï¼Œæ— ä»»ä½•æ§åˆ¶ç­–ç•¥ï¼‰
                print("ğŸ” åŸºçº¿ç¿»è¯‘ï¼ˆçº¯LLMï¼Œæ— æ§åˆ¶ç­–ç•¥ï¼‰...")
                baseline_agent = BaselineTranslationAgent(locale=tgt_lang)
                baseline_result = await baseline_agent.execute({
                    'source_text': source,
                    'source_lang': src_lang,
                    'target_lang': tgt_lang
                }, None)
                
                result['trace']['baseline'] = {
                    'translated_text': baseline_result.translated_text,
                    'confidence': baseline_result.confidence
                }
                result['final'] = baseline_result.translated_text
                print(f"   ç»“æœ: {result['final']}\n")
            
            result['success'] = True
            
        except Exception as e:
            print(f"âŒ ç¿»è¯‘å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            result['success'] = False
            result['error'] = str(e)
            result['final'] = source
        
        return result
    
    async def _run_terminology_round(self, text: str, src_lang: str, tgt_lang: str, use_termbase: bool) -> Dict[str, Any]:
        """æœ¯è¯­å±‚ç¿»è¯‘ï¼ˆä½¿ç”¨ terminology workflowï¼‰"""
        # ç›´æ¥è°ƒç”¨ terminology workflow
        result = await run_terminology_workflow(
            text=text,
            src_lang=src_lang,
            tgt_lang=tgt_lang,
            use_termbase=use_termbase,
            db_path=self.config.get('term_db', 'terms.db'),
            verbose=self.verbose,
            selection_config=self.selection_config
        )
        
        # ä¿å­˜æœ¯è¯­è¡¨ä¾›å¥æ³•å±‚ä½¿ç”¨
        if 'termTable' in result:
            self._current_term_table = result['termTable']
        
        return result
    
    async def _run_syntax_round(self, source_text: str, target_text: str, src_lang: str, tgt_lang: str) -> Dict[str, Any]:
        """å¥æ³•å±‚ç¿»è¯‘ï¼ˆä½¿ç”¨ syntax workflowï¼‰
        
        Args:
            source_text: æºæ–‡æœ¬ï¼ˆåŸå§‹è¾“å…¥ï¼‰
            target_text: ç›®æ ‡æ–‡æœ¬ï¼ˆç¬¬ä¸€è½®ç¿»è¯‘ç»“æœï¼‰
            src_lang: æºè¯­è¨€
            tgt_lang: ç›®æ ‡è¯­è¨€
        """
        # è·å–æœ¯è¯­è¡¨ï¼ˆç”¨äºä¿æŠ¤ï¼‰
        term_table = getattr(self, '_current_term_table', [])
        
        # ç›´æ¥è°ƒç”¨ syntax workflow
        result = await run_syntactic_workflow(
            source_text=source_text,
            target_text=target_text,
            src_lang=src_lang,
            tgt_lang=tgt_lang,
            term_table=term_table,
            verbose=self.verbose,
            selection_config=self.selection_config
        )
        
        return result
    
    async def _run_discourse_round(self, translated_text: str, src_lang: str, tgt_lang: str, trace: Dict, use_tm: bool=True) -> Dict[str, Any]:
        """ç¯‡ç« å±‚æ•´åˆï¼ˆä½¿ç”¨ discourse workflowï¼‰
        
        Args:
            translated_text: ç¬¬äºŒè½®ç¿»è¯‘ç»“æœ
            src_lang: æºè¯­è¨€
            tgt_lang: ç›®æ ‡è¯­è¨€
            trace: ä¹‹å‰çš„traceä¿¡æ¯
            use_tm: æ˜¯å¦ä½¿ç”¨ç¿»è¯‘è®°å¿†
        """
        # è·å–åŸå§‹æºæ–‡æœ¬
        source_text = trace.get('r1', {}).get('source_text', translated_text)
        
        # ç›´æ¥è°ƒç”¨ discourse workflow
        result = await run_discourse_workflow(
            source_text=source_text,
            current_translation=translated_text,
            src_lang=src_lang,
            tgt_lang=tgt_lang,
            trace=trace,
            use_tm=use_tm,
            verbose=self.verbose,
            selection_config=self.selection_config
        )
        
        return result


async def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='æ³•å¾‹æ–‡æœ¬ç¿»è¯‘å·¥å…·ï¼ˆæœ¬åœ°ç‰ˆï¼‰')
    parser.add_argument('--source', required=True, help='æºæ–‡æœ¬')
    parser.add_argument('--src-lang', default='zh', help='æºè¯­è¨€ (é»˜è®¤: zh)')
    parser.add_argument('--tgt-lang', default='en', help='ç›®æ ‡è¯­è¨€ (é»˜è®¤: en)')
    parser.add_argument('--hierarchical', action='store_true', default=True, help='ä½¿ç”¨å±‚çº§ç¿»è¯‘')
    parser.add_argument('--no-hierarchical', dest='hierarchical', action='store_false', help='ä¸ä½¿ç”¨å±‚çº§ç¿»è¯‘')
    parser.add_argument('--use-termbase', action='store_true', default=True, help='ä½¿ç”¨æœ¯è¯­åº“')
    parser.add_argument('--term-db', default='terms.db', help='æœ¯è¯­åº“è·¯å¾„ (é»˜è®¤: terms.db)')
    parser.add_argument('--no-termbase', dest='use_termbase', action='store_false', help='ä¸ä½¿ç”¨æœ¯è¯­åº“')
    parser.add_argument('--use-tm', action='store_true', default=True, help='ä½¿ç”¨ç¿»è¯‘è®°å¿†')
    parser.add_argument('--no-tm', dest='use_tm', action='store_false', help='ä¸ä½¿ç”¨ç¿»è¯‘è®°å¿†')
    parser.add_argument('--output', '-o', help='è¾“å‡ºæ–‡ä»¶è·¯å¾„ (JSONæ ¼å¼)')
    parser.add_argument('--verbose', '-v', action='store_true', help='è¯¦ç»†è¾“å‡º')
    
    # LLMé€‰æ‹©å™¨é…ç½®
    parser.add_argument('--selection-layers', type=str, default='none',
                        help='å¯ç”¨LLMå€™é€‰é€‰æ‹©çš„å±‚çº§ (å¯é€‰: terminology, syntax, discourse, all, last, none; é»˜è®¤: none)')
    parser.add_argument('--num-candidates', type=int, default=3,
                        help='æ¯å±‚ç”Ÿæˆçš„å€™é€‰æ•°é‡ (é»˜è®¤: 3)')
    
    # é—¨æ§å‚æ•°
    parser.add_argument('--gating-layers', type=str, default='all',
                        help='å¯ç”¨é—¨æ§çš„å±‚çº§: none/all/terminology,syntax,discourse (é»˜è®¤: all)')
    parser.add_argument('--term-gate-threshold', type=float, default=0.8,
                        help='æœ¯è¯­ç½®ä¿¡åº¦é—¨æ§é˜ˆå€¼ï¼Œä½äºæ­¤å€¼çš„æœ¯è¯­è¢«è¿‡æ»¤ï¼ˆé»˜è®¤: 0.8ï¼‰')
    parser.add_argument('--syntax-gate-threshold', type=float, default=0.9,
                        help='å¥æ³•è¯„ä¼°åˆ†æ•°é—¨æ§é˜ˆå€¼ï¼Œé«˜äºæ­¤å€¼ä¸ä¿®æ”¹ï¼ˆé»˜è®¤: 0.9ï¼‰')
    parser.add_argument('--discourse-gate-threshold', type=float, default=0.9,
                        help='ç¯‡ç« è¯„ä¼°åˆ†æ•°é—¨æ§é˜ˆå€¼ï¼Œé«˜äºæ­¤å€¼ä¸ä¿®æ”¹ï¼ˆé»˜è®¤: 0.9ï¼‰')
    parser.add_argument('--tm-gate-threshold', type=float, default=0.4,
                        help='TMç›¸ä¼¼åº¦é—¨æ§é˜ˆå€¼ï¼Œä½äºæ­¤å€¼çš„TMè¢«è¿‡æ»¤ï¼ˆé»˜è®¤: 0.4ï¼‰')
    
    # è´¨é‡è¯„ä¼°å‚æ•°
    parser.add_argument('--reference', help='å‚è€ƒè¯‘æ–‡ï¼ˆç”¨äºè´¨é‡è¯„ä¼°ï¼‰')
    parser.add_argument('--evaluate', action='store_true', 
                        help='å¯ç”¨è´¨é‡è¯„ä¼°ï¼šå¯¹æ¯”ç¿»è¯‘ç»“æœå’Œå‚è€ƒè¯‘æ–‡ï¼Œç»™å‡ºæ”¹è¿›å»ºè®®ï¼ˆéœ€è¦æä¾›--referenceï¼‰')
    
    args = parser.parse_args()
    
    # æ£€æŸ¥å¿…éœ€çš„ç¯å¢ƒå˜é‡
    import os
    api_key = os.getenv('OPENAI_API_KEY', '').strip()
    if not api_key:
        print("\n" + "=" * 60)
        print("âŒ é”™è¯¯ï¼šæœªè®¾ç½® OPENAI_API_KEY ç¯å¢ƒå˜é‡")
        print("=" * 60)
        print("\nè¯·è®¾ç½® API å¯†é’¥åå†è¿è¡Œï¼š")
        print("  export OPENAI_API_KEY='your-api-key-here'")
        print("\næˆ–è€…åœ¨ .env æ–‡ä»¶ä¸­é…ç½®ï¼š")
        print("  OPENAI_API_KEY=your-api-key-here")
        print("=" * 60 + "\n")
        return 1
    
    # æ„å»ºé…ç½®
    config = {
        'hierarchical': args.hierarchical,
        'useTermBase': args.use_termbase,
        'useTM': args.use_tm,
        'selection_layers': args.selection_layers,
        'num_candidates': args.num_candidates,
        'gating_layers': args.gating_layers,
        'term_gate_threshold': args.term_gate_threshold,
        'syntax_gate_threshold': args.syntax_gate_threshold,
        'discourse_gate_threshold': args.discourse_gate_threshold,
        'tm_gate_threshold': args.tm_gate_threshold,
        'term_db': args.term_db
    }
    
    # æ˜¾ç¤ºæ§åˆ¶æœºåˆ¶é…ç½®ï¼ˆå¦‚æœå¯ç”¨ï¼‰
    if (args.selection_layers and args.selection_layers != 'none') or (args.gating_layers and args.gating_layers != 'none'):
        print(f"\n{'='*60}")
        print(f"ç¿»è¯‘æ§åˆ¶æœºåˆ¶é…ç½®")
        print(f"{'='*60}")
        if args.selection_layers and args.selection_layers != 'none':
            print(f"âœ“ LLMå€™é€‰é€‰æ‹©: {args.selection_layers} å±‚çº§, {args.num_candidates} ä¸ªå€™é€‰")
        else:
            print(f"âœ“ LLMå€™é€‰é€‰æ‹©: æœªå¯ç”¨")
        
        if args.gating_layers and args.gating_layers != 'none':
            print(f"âœ“ é—¨æ§æœºåˆ¶: {args.gating_layers} å±‚çº§")
            print(f"  - æœ¯è¯­é˜ˆå€¼: {args.term_gate_threshold}")
            print(f"  - å¥æ³•é˜ˆå€¼: {args.syntax_gate_threshold}")
            print(f"  - ç¯‡ç« é˜ˆå€¼: {args.discourse_gate_threshold}")
            print(f"  - TMé˜ˆå€¼: {args.tm_gate_threshold}")
        else:
            print(f"âœ“ é—¨æ§æœºåˆ¶: æœªå¯ç”¨")
        print(f"{'='*60}\n")
    
    # åˆ›å»ºç¿»è¯‘å™¨
    translator = SimpleTranslator(config, verbose=args.verbose)
    
    # æ‰§è¡Œç¿»è¯‘
    result = await translator.translate(args.source, args.src_lang, args.tgt_lang)
    
    # è¾“å‡ºç»“æœ
    print(f"\n{'='*60}")
    print(f"ç¿»è¯‘ç»“æœ")
    print(f"{'='*60}")
    print(f"æºæ–‡æœ¬: {result['source']}")
    print(f"è¯‘æ–‡:   {result['final']}")
    
    if args.verbose:
        print(f"\nç»Ÿè®¡ä¿¡æ¯:")
        if result['trace'].get('r1'):
            r1 = result['trace']['r1']
            print(f"  æœ¯è¯­å±‚: {r1.get('terms_found', 0)} ä¸ªæœ¯è¯­, ç½®ä¿¡åº¦: {r1.get('confidence', 0):.2f}")
        if result['trace'].get('r2'):
            r2 = result['trace']['r2']
            print(f"  å¥æ³•å±‚: {r2.get('patterns', 0)} ä¸ªæ¨¡å¼, ç½®ä¿¡åº¦: {r2.get('confidence', 0):.2f}")
        if result['trace'].get('r3'):
            r3 = result['trace']['r3']
            print(f"  ç¯‡ç« å±‚: TMåŒ¹é… {r3.get('tm_matches', 0)} ä¸ª, åº”ç”¨ {r3.get('tm_applied', 0)} ä¸ª, åˆ†æ•°: {r3.get('discourse_score', 0):.2f}")
    else:
        if result['trace'].get('r1', {}).get('terms_found', 0) > 0:
            print(f"æ‰¾åˆ°æœ¯è¯­: {result['trace']['r1']['terms_found']} ä¸ª")
    
    print(f"{'='*60}\n")
    
    # è´¨é‡è¯„ä¼°ï¼ˆå¦‚æœæä¾›äº†å‚è€ƒè¯‘æ–‡ä¸”å¯ç”¨äº†è¯„ä¼°ï¼‰
    if args.evaluate and args.reference and result['success']:
        print(f"\n{'='*60}")
        print(f"ğŸ“Š è´¨é‡è¯„ä¼°ï¼ˆå¯¹æ¯”å‚è€ƒè¯‘æ–‡ï¼‰")
        print(f"{'='*60}")
        print(f"æºæ–‡æœ¬: {result['source']}")
        print(f"è¯‘æ–‡: {result['final']}")
        print(f"å‚è€ƒè¯‘æ–‡: {args.reference}")
        print(f"\næ­£åœ¨è¯„ä¼°...")
        
        try:
            assessor = QualityAssessorAgent(locale=args.tgt_lang)
            assessment = await assessor.execute({
                'source_text': result['source'],
                'translation': result['final'],
                'reference': args.reference,
                'source_lang': args.src_lang,
                'target_lang': args.tgt_lang
            }, None)
            
            # æ˜¾ç¤ºè¯„ä¼°ç»“æœ
            print(f"\nâœ… è¯„ä¼°å®Œæˆï¼")
            print(f"\n{'â”€'*60}")
            print(f"ğŸ“ˆ è¯„åˆ†è¯¦æƒ…")
            print(f"{'â”€'*60}")
            print(f"  æ€»ä½“è¯„åˆ†: {assessment.overall_score:.2%} {'â­' * int(assessment.overall_score * 5)}")
            print(f"  - å‡†ç¡®æ€§:   {assessment.accuracy_score:.2%}")
            print(f"  - æµç•…æ€§:   {assessment.fluency_score:.2%}")
            print(f"  - æœ¯è¯­:     {assessment.terminology_score:.2%}")
            print(f"  - é£æ ¼:     {assessment.style_score:.2%}")
            
            if assessment.strengths:
                print(f"\n{'â”€'*60}")
                print(f"âœ¨ ç¿»è¯‘ä¼˜ç‚¹")
                print(f"{'â”€'*60}")
                for i, strength in enumerate(assessment.strengths, 1):
                    print(f"  {i}. {strength}")
            
            if assessment.weaknesses:
                print(f"\n{'â”€'*60}")
                print(f"âš ï¸  éœ€è¦æ”¹è¿›")
                print(f"{'â”€'*60}")
                for i, weakness in enumerate(assessment.weaknesses, 1):
                    print(f"  {i}. {weakness}")
            
            if assessment.suggestions:
                print(f"\n{'â”€'*60}")
                print(f"ğŸ’¡ æ”¹è¿›å»ºè®®")
                print(f"{'â”€'*60}")
                for i, suggestion in enumerate(assessment.suggestions, 1):
                    print(f"  {i}. {suggestion}")
            
            if args.verbose and assessment.detailed_comparison:
                print(f"\n{'â”€'*60}")
                print(f"ğŸ“ è¯¦ç»†å¯¹æ¯”åˆ†æ")
                print(f"{'â”€'*60}")
                print(f"  {assessment.detailed_comparison}")
            
            print(f"\n{'='*60}\n")
            
            # å°†è¯„ä¼°ç»“æœæ·»åŠ åˆ°ç»“æœä¸­
            result['quality_assessment'] = {
                'overall_score': assessment.overall_score,
                'accuracy_score': assessment.accuracy_score,
                'fluency_score': assessment.fluency_score,
                'terminology_score': assessment.terminology_score,
                'style_score': assessment.style_score,
                'strengths': assessment.strengths,
                'weaknesses': assessment.weaknesses,
                'suggestions': assessment.suggestions,
                'detailed_comparison': assessment.detailed_comparison
            }
            
        except Exception as e:
            print(f"âŒ è´¨é‡è¯„ä¼°å¤±è´¥: {e}")
            if args.verbose:
                import traceback
                traceback.print_exc()
    elif args.evaluate and not args.reference:
        print(f"\nâš ï¸  æç¤º: å¯ç”¨äº†è´¨é‡è¯„ä¼° (--evaluate) ä½†æœªæä¾›å‚è€ƒè¯‘æ–‡ (--reference)")
        print(f"    è¯·ä½¿ç”¨: --reference 'å‚è€ƒè¯‘æ–‡å†…å®¹' æ¥å¯ç”¨è´¨é‡è¯„ä¼°\n")
    
    # ä¿å­˜åˆ°æ–‡ä»¶
    if args.output:
        with open(args.output, 'w', encoding='utf-8') as f:
            json.dump(result, f, ensure_ascii=False, indent=2)
        print(f"âœ… ç»“æœå·²ä¿å­˜åˆ°: {args.output}\n")
    
    return 0 if result['success'] else 1


if __name__ == "__main__":
    exit_code = asyncio.run(main())
    sys.exit(exit_code)

